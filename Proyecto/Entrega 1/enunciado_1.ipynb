{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos**\n",
    "\n",
    "### üë®‚Äçüè´üë©‚Äçüè´ Cuerpo Docente:\n",
    "\n",
    "- Profesor: Sebasti√°n Tinoco, Stefano Schiappacasse\n",
    "- Auxiliar: Melanie Pe√±a Torres, Valentina Rojas Osorio\n",
    "- Ayudante: Valentina Zu√±iga, √Ångelo Mu√±oz \n",
    "\n",
    "### üë®‚Äçüíªüë©‚Äçüíª Estudiantes:\n",
    "- Estudiante n¬∞1: Camila Salas R.\n",
    "- Estudiante n¬∞2: Ignacio Negrete S.\n",
    "\n",
    "_Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Enunciado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src='https://github.com/MDS7202/MDS7202/blob/main/recursos/2025-01/proyecto/proyecto.png?raw=true' style=\"border-radius: 12px\"> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el competitivo universo de las bebidas gaseosas, la empresa **SodAI Drinks ü•§** ha logrado destacarse por su creatividad, diversidad de productos y enfoque centrado en el cliente. Ofrece una extensa gama de bebidas carbonatadas que abarca distintos segmentos del mercado: desde productos premium en presentaciones sofisticadas, hasta gaseosas accesibles para el consumo masivo, disponibles en diversos tama√±os y tipos de envases. \n",
    "\n",
    "La compa√±√≠a opera en m√∫ltiples regiones y zonas, sirviendo a una variedad de puntos de venta que incluyen desde tiendas de conveniencia y minimarkets hasta el canal fr√≠o tradicional. Cada tipo de cliente tiene sus particularidades: algunos reciben entregas hasta 4 veces por semana, mientras que otros son visitados por la fuerza de ventas solo una vez semanalmente. Esta diversidad de perfiles representa tanto una oportunidad como un desaf√≠o comercial: ¬øc√≥mo saber qu√© productos tienen m√°s chances de ser comprados por cada cliente en un momento dado?\n",
    "\n",
    "Con el objetivo de aumentar la facturaci√≥n de forma inteligente y mejorar la eficiencia de su estrategia de ventas, **SodAI Drinks** decide crear una nueva c√©lula interna de innovaci√≥n: el equipo **Deep Drinkers ü§ñ**, cuyo prop√≥sito es aplicar ciencia de datos para anticiparse a las necesidades del cliente y potenciar el negocio desde una perspectiva basada en informaci√≥n.\n",
    "\n",
    "El coraz√≥n de esta iniciativa es el desarrollo de un sistema predictivo personalizado para cada cliente. Para ello, **Deep Drinkers** convoca a un equipo de Data Scientists y especialistas en *machine learning* con una misi√≥n clara: construir un modelo predictivo que, cada semana, pueda estimar la probabilidad de compra de cada producto del portafolio para cada cliente activo.\n",
    "\n",
    "El modelo deber√° tener en cuenta m√∫ltiples factores, incluyendo:\n",
    "- **Tipo de cliente**, ej. \"TIENDA DE CONVENIENCIA\", \"MINIMARKET\".\n",
    "- **Frecuencia de entregas y visitas**, indicadores del nivel de actividad comercial.\n",
    "- **Ubicaci√≥n geogr√°fica** (por regi√≥n y zona).\n",
    "- **Preferencias hist√≥ricas de consumo**, inferidas por patrones de compra anteriores.\n",
    "- **Caracter√≠sticas del producto**, como marca, categor√≠a, segmento, tipo de envase y tama√±o\n",
    "\n",
    "El objetivo final es que, **cada semana**, se genere una tabla de productos priorizados: para cada cliente, un listado de productos ordenado por su probabilidad estimada de compra. Esta informaci√≥n ser√° enviada al equipo comercial, que podr√° usarla en call center, para incrementar las chances de concretar ventas al ofrecer justo lo que el cliente probablemente quiere comprar.\n",
    "\n",
    "Este proyecto representa un cambio de paradigma en la forma en que **SodAI Drinks** gestiona su fuerza de ventas: de un enfoque reactivo y generalista, a uno proactivo, basado en datos y profundamente personalizado. As√≠, la empresa no solo espera aumentar su rentabilidad, sino tambi√©n construir relaciones m√°s s√≥lidas con sus clientes, ofreci√©ndoles recomendaciones m√°s relevantes y oportunas.\n",
    "\n",
    "Para lograr lo anterior, el equipo **Deep Drinkers** contar√° con los siguientes conjuntos de datos, junto a sus respectivos atributos:\n",
    "\n",
    "- **Datos transaccionales** (`transacciones.parquet`): contiene el historial de compras realizadas por los clientes.\n",
    "\t- `customer_id`: identificador √∫nico del cliente que realiz√≥ la compra.\n",
    "\t- `product_id`: identificador √∫nico del producto comprado.\n",
    "\t- `purchase_date`: fecha en que se realiz√≥ la transacci√≥n.\n",
    "\t- `order_id`: identificar de la orden de su pedido.\n",
    "\t- `payment`\tmonto total pagado por la transacci√≥n.\n",
    "\n",
    "- **Datos de clientes** (`clientes.parquet`): incluye las caracter√≠sticas de cada cliente.\n",
    "\t- `customer_id`: identificador √∫nico del cliente.\n",
    "\t- `region_id`: identificador de la regi√≥n geogr√°fica donde se encuentra el cliente.\n",
    "\t- `customer_type`: tipo de cliente seg√∫n el canal comercial, por ejemplo, ‚ÄúTIENDA DE CONVENIENCIA‚Äù.\n",
    "\t- `Y`: coordenada geogr√°fica de latitud.\n",
    "\t- `X`: coordenada geogr√°fica de longitud.\n",
    "\t- `num_deliver_per_week`: cantidad de entregas semanales que recibe el cliente.\n",
    "\t- `num_visit_per_week`: frecuencia de visitas de la fuerza de ventas por semana.\n",
    "\n",
    "- **Datos de productos** (`productos.parquet`): describe las caracter√≠sticas de los productos del portafolio.\n",
    "\t- `product_id`: identificador √∫nico del producto.\n",
    "\t- `brand`: marca comercial del producto.\n",
    "\t- `category`: categor√≠a general del producto, como ‚ÄúBEBIDAS CARBONATADAS‚Äù.\n",
    "\t- `sub_category`: subcategor√≠a dentro de la categor√≠a principal, por ejemplo, ‚ÄúGASEOSAS‚Äù.\n",
    "\t- `segment`: segmento de mercado al que pertenece el producto, como ‚ÄúPREMIUM‚Äù.\n",
    "\t- `package`: tipo de envase del producto.\n",
    "\t- `size`: tama√±o del producto en litros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Reglas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://media1.tenor.com/m/0Qtv_cQ4ITsAAAAd/necohaus-grey-name.gif\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "El proyecto consta de **dos entregas parciales** y una **entrega final** en donde la primera entrega la idea es poder reflejar lo aprendido durante la primera mitad del curso, que ser√° sobre los contenidos relacionados a *machine learning*, la segunda ser√° sobre los contenidos de la segunda mitad del curso relacionados a *MLOps* y por √∫ltimo la entrega final constar√° de dos partes, donde la primera ser√° relacionada con experimentaci√≥n sobre nuevos datasets que ser√°n disponibilizados durante las √∫ltimas semanas del curso de manera incremental y una segunda parte que ser√° el informe final escrito que deber√° explicar el desarrollo del proyecto completo, como tambien los resultados y an√°lisis de los experimentos realizados sobre los datasets incrementales. La idea es que todo el c√≥digo est√© desarrollado durante las primeras dos entregas y luego en la entrega final s√≥lo se ejecute el c√≥digo sobre nuevos conjuntos de datos.\n",
    "\n",
    "La idea de generar el proyecto por etapas es poder aliviar la carga de trabajo en las √∫ltimas semanas del semestre donde sabemos que est√°n muy cargado con entregas, pruebas y ex√°menes de otros ramos, y as√≠ garantizamos que habiendo la desarrollado las dos primeras entregas parciales, tendr√°n el grueso del proyecto listo para luego experimentar y documentar.\n",
    "\n",
    "---\n",
    "### **Fechas de entrega**\n",
    "- **Entrega parcial 1**: 14 de Mayo\n",
    "- **Entrega parcial 2**: Por definir\n",
    "- **Entrega final**: Por definir\n",
    "\n",
    "---\n",
    "\n",
    "### **Requisitos del proyecto**\n",
    "- **Grupos**: Formar equipos de **2 personas**. No se aceptar√°n trabajos individuales o grupos con m√°s integrantes.\n",
    "- **Consultas**: Cualquier duda fuera del horario de clases debe ser planteada en el foro correspondiente. Los mensajes enviados al equipo docente ser√°n respondidos √∫nicamente por este medio. Por favor, revisen las respuestas anteriores en el foro antes de realizar nuevas consultas.\n",
    "- **Plagio**: La copia o reutilizaci√≥n no autorizada de trabajos de otros grupos est√° **estrictamente prohibida**. El incumplimiento de esta norma implicar√° la anulaci√≥n inmediata del proyecto y una posible sanci√≥n acad√©mica.\n",
    "- **Material permitido**: Pueden usar cualquier material del curso, ya sea notas, lecturas, c√≥digos, o referencias proporcionadas por los docentes, que consideren √∫til para el desarrollo del proyecto.\n",
    "\n",
    "---\n",
    "\n",
    "### **Entregables y etapas**\n",
    "\n",
    "#### **1. Entrega Parcial 1**  \n",
    "- Dispondr√°n de los archivos de datos **productos.parquet**, **clientes.parquet** y **transacciones.parquet** para el modelamiento inicial.  \n",
    "- Utilizar√°n estos archivos para desarrollar lo solicitado para la entrega 1. \n",
    "- En esta etapa, se espera que apliquen todos los conocimientos aprendidos durante la primera parte del curso relacionados con *machine learning*.\n",
    "- **Informe**: No se exige un avance del informe en esta etapa, s√≥lo un notebook con su desarrollo actual, pero se **recomienda comenzar** a redactar el informe final en paralelo para disminuir la carga acad√©mica en las etapas posteriores.  \n",
    "\n",
    "#### **2. Entrega Parcial 2**  \n",
    "- En esta entrega, deber√°n aplicar los conocimientos aprendidos durante la segunda mitad del curso sobre *MLOps*  \n",
    "- Se espera que implementen estos conocimientos para desplegar su modelo elegido en la primera entrega y crear *pipelines* automatizados que simulen un entorno productivo.\n",
    "- **Informe**: similar a la primera etapa, no se exige un avance del informe, pero se **recomienda avanzar con su redacci√≥n** para evitar una acumulaci√≥n de trabajo en la etapa final.  \n",
    "\n",
    "#### **3. Entrega Final**  \n",
    "- En la entrega final, deber√°n realizar dos etapas:\n",
    "\t- La primera etapa es sobre experimentaci√≥n utilizando datasets incrementales que se ir√°n disponibilizando de manera parcial, para que vayan generando predicciones con su modelo ya desplegado. El objetivo de esta etapa es poder testear su soluci√≥n *end-to-end* y que vayan analizando los resultados obtenidos a medida que se van agregando m√°s datos.\n",
    "\t- La segunda etapa consiste en redactar un informe final que deber√° explicar el desarrollo completo de tu proyecto y un an√°lisis profundo de sus resultados de experimentaci√≥n. Este informe debera incluir a lo menos las siguientes secciones:\n",
    "\t\t- An√°lisis exploratorio de datos  \n",
    "\t\t- Metodolog√≠a aplicada  \n",
    "\t\t- Selecci√≥n y entrenamiento de modelos  \n",
    "\t\t- Evaluaci√≥n de resultados  \n",
    "\t\t- Optimizaci√≥n de modelos\n",
    "\t\t- Interpretabilidad\n",
    "\t\t- Re-entrenamiento\n",
    "\t\t- Tracking con MLFlow\n",
    "\t\t- Creaci√≥n de la aplicaci√≥n web con Gradio y FastAPI\n",
    "\n",
    "Es **altamente recomendable** ir redactando el informe en paralelo al desarrollo de los modelos para garantizar que toda la informaci√≥n relevante quede documentada adecuadamente.  \n",
    "\n",
    "### Nota Final\n",
    "\n",
    "La calificaci√≥n final de su proyecto se calcular√° utilizando la siguiente ponderaci√≥n: \n",
    "\n",
    "$$Nota Final = 0.30 * EntregaParcial1 + 0.40 * EntregaParcial2 + 0.30 * EntregaFinal$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Instrucciones importantes**\n",
    "\n",
    "1. **Formato del informe**:  \n",
    "   - El informe debe estar integrado dentro de un **Jupyter Notebook**. No es necesario subirlo a una plataforma externa, pero debe cumplir con los siguientes requisitos:  \n",
    "     - Estructura clara y ordenada.  \n",
    "     - C√≥digo acompa√±ado de explicaciones detalladas.  \n",
    "     - Resultados presentados de forma visual y anal√≠tica.  \n",
    "\n",
    "2. **Descuento por informes deficientes**:  \n",
    "   - Cualquier secci√≥n del informe que no tenga una explicaci√≥n adecuada o no respete el formato ser√° penalizada con un descuento en la nota. Esto incluye c√≥digo sin comentarios o an√°lisis que no sean coherentes con los resultados presentados.\n",
    "   - Comentarios sin formatear de ChatGPT o herramientas similares ser√°n penalizados (e.g: \"Inserta tu modelo ac√°\", etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¨ Entrega Parcial 1 (30% del Proyecto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì™ Fecha de Entrega: 14 de Mayo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Abstract [0.25 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.redd.it/h5ptnsyabqvd1.gif\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci√≥n, deben redactar un Abstract claro y conciso para su proyecto. El Abstract debe responder a las siguientes preguntas clave:\n",
    "\n",
    "- **Descripci√≥n del problema**: ¬øCu√°l es el objetivo del proyecto? ¬øQu√© se intenta predecir o analizar?\n",
    "- **Datos de entrada**: ¬øQu√© datos tienen disponibles? ¬øCu√°les son sus principales caracter√≠sticas?\n",
    "- **M√©trica de evaluaci√≥n**: ¬øC√≥mo medir√°n el desempe√±o de sus modelos? Expliquen por qu√© eligieron esta m√©trica bas√°ndose en el an√°lisis exploratorio de los datos.\n",
    "- **Modelos y transformaciones**: ¬øQu√© modelos utilizar√°n y por qu√©? ¬øQu√© transformaciones o preprocesamientos aplicaron a los datos?\n",
    "- **Resultados generales**: ¬øEl modelo final cumpli√≥ con los objetivos del proyecto? ¬øCu√°les fueron las conclusiones m√°s importantes?\n",
    "\n",
    "**Importante**: Escriban esto despues de haber resuelto el resto de la tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [Escriba aqu√≠ su Abstract]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Pre-procesamiento [0.5 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media0.giphy.com/media/10zsjaH4g0GgmY/giphy.gif?cid=6c09b9523xtlunksc9amikw09zk1bmiqwjqnt70ae82rk877&ep=v1_gifs_search&rid=giphy.gif&ct=g\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como en muchos otros problemas de negocio, los datos probablemente deben ser pre procesados antes de aplicar cualquier t√©cnica de anal√≠tica. Bajo esa premisa, en esta secci√≥n deben desarrollar c√≥digo que les permita **preparar los datos** de tal forma que les permita resolver el problema planteado. Para esto, pueden aplicar procesamientos como:\n",
    "\n",
    "- Transformaciones de tipo de dato (str, int, etc)\n",
    "- Cruce de informaci√≥n\n",
    "- Eliminaci√≥n de duplicados\n",
    "- Filtros de fila y/o columnas\n",
    "\n",
    "*Hint: ¬øQu√© forma deber√≠a tener la data para resolver un problema de aprendizaje supervisado?*\n",
    "\n",
    "Todo proceso llevado a cabo debe estar bien documentado y justificado en el informe, explicando el por qu√© se decidi√≥ realizar en funcion de los datos presentados y los objetivos planteados del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias que vamos a usar en la seccion\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, FunctionTransformer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuestros datasets\n",
    "clientes  = pd.read_parquet('clientes.parquet')\n",
    "productos = pd.read_parquet('productos.parquet')\n",
    "transacciones = pd.read_parquet('transacciones.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1569 entries, 10705 to 12273\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   customer_id           1569 non-null   int64  \n",
      " 1   region_id             1569 non-null   int64  \n",
      " 2   zone_id               1569 non-null   int64  \n",
      " 3   customer_type         1569 non-null   object \n",
      " 4   Y                     1569 non-null   float64\n",
      " 5   X                     1568 non-null   float64\n",
      " 6   num_deliver_per_week  1569 non-null   int64  \n",
      " 7   num_visit_per_week    1569 non-null   int64  \n",
      "dtypes: float64(2), int64(5), object(1)\n",
      "memory usage: 110.3+ KB\n"
     ]
    }
   ],
   "source": [
    "clientes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 971 entries, 0 to 970\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   product_id    971 non-null    int64  \n",
      " 1   brand         971 non-null    object \n",
      " 2   category      971 non-null    object \n",
      " 3   sub_category  971 non-null    object \n",
      " 4   segment       971 non-null    object \n",
      " 5   package       971 non-null    object \n",
      " 6   size          971 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 53.2+ KB\n"
     ]
    }
   ],
   "source": [
    "productos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 254936 entries, 124 to 7712548\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   customer_id    254936 non-null  int64         \n",
      " 1   product_id     254936 non-null  int64         \n",
      " 2   order_id       254936 non-null  int64         \n",
      " 3   purchase_date  254936 non-null  datetime64[ns]\n",
      " 4   items          254936 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3)\n",
      "memory usage: 11.7 MB\n"
     ]
    }
   ],
   "source": [
    "transacciones.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que podemos notar es que tenemos valores nulos en el dataset. Luego la idea ahora es ampliar la base de transacciones, a√±adiendo la informacion correspondiente al cliente que reliza la transaccion y al producto transado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 254936 entries, 0 to 254935\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   customer_id           254936 non-null  int64         \n",
      " 1   product_id            254936 non-null  int64         \n",
      " 2   order_id              254936 non-null  int64         \n",
      " 3   purchase_date         254936 non-null  datetime64[ns]\n",
      " 4   items                 254936 non-null  float64       \n",
      " 5   brand                 254936 non-null  object        \n",
      " 6   category              254936 non-null  object        \n",
      " 7   sub_category          254936 non-null  object        \n",
      " 8   segment               254936 non-null  object        \n",
      " 9   package               254936 non-null  object        \n",
      " 10  size                  254936 non-null  float64       \n",
      " 11  region_id             254936 non-null  int64         \n",
      " 12  zone_id               254936 non-null  int64         \n",
      " 13  customer_type         254936 non-null  object        \n",
      " 14  Y                     254936 non-null  float64       \n",
      " 15  X                     254936 non-null  float64       \n",
      " 16  num_deliver_per_week  254936 non-null  int64         \n",
      " 17  num_visit_per_week    254936 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(7), object(6)\n",
      "memory usage: 37.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(transacciones,productos,how='left',on='product_id')\n",
    "df = pd.merge(df,clientes,how='left',on='customer_id')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion eliminamos registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos la base completa nos gustaria hacer un visualizacion de esta data, para saber si es necesario eliminar columnas irrelevantes o realizar algunas transformaciones. Luego dicha visualizacion puede ser complementada con un analisis por quartiles para enriquecer la exploracion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ocupamos la funcion del lab4\n",
    "# Se observa la distribuci√≥n de las distintas variables\n",
    "columns = df.drop(columns=['customer_id','product_id','order_id']).columns\n",
    "fig = make_subplots(rows=5, cols=3, subplot_titles=columns)\n",
    "\n",
    "# Se agregan las distribuciones\n",
    "for i in range(len(columns)):\n",
    "    fig.add_trace(go.Histogram(x=df[columns[i]]), row=i//3 + 1, col=i%3 + 1)\n",
    "\n",
    "fig.update_layout(height=1000, width=1000, title_text=\"Distribuci√≥n de variables num√©ricas\")\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.  ,  0.31,  0.66,  0.25,  0.33, 20.  ,  0.5 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items</th>\n",
       "      <th>size</th>\n",
       "      <th>region_id</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>Y</th>\n",
       "      <th>X</th>\n",
       "      <th>num_deliver_per_week</th>\n",
       "      <th>num_visit_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>254051.000000</td>\n",
       "      <td>254051.000000</td>\n",
       "      <td>254051.0</td>\n",
       "      <td>254051.0</td>\n",
       "      <td>254051.000000</td>\n",
       "      <td>254051.000000</td>\n",
       "      <td>254051.000000</td>\n",
       "      <td>254051.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.375755</td>\n",
       "      <td>0.675775</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5148.0</td>\n",
       "      <td>-46.641522</td>\n",
       "      <td>-107.777588</td>\n",
       "      <td>3.164680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.080519</td>\n",
       "      <td>1.088911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.029226</td>\n",
       "      <td>2.030981</td>\n",
       "      <td>0.392777</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-399.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5148.0</td>\n",
       "      <td>-109.002508</td>\n",
       "      <td>-108.620920</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5148.0</td>\n",
       "      <td>-46.577054</td>\n",
       "      <td>-107.930286</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5148.0</td>\n",
       "      <td>-46.552598</td>\n",
       "      <td>-107.892716</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5148.0</td>\n",
       "      <td>-46.489940</td>\n",
       "      <td>-107.856730</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.333333</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5148.0</td>\n",
       "      <td>-46.308598</td>\n",
       "      <td>-46.442785</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               items           size  region_id   zone_id              Y  \\\n",
       "count  254051.000000  254051.000000   254051.0  254051.0  254051.000000   \n",
       "mean        4.375755       0.675775       80.0    5148.0     -46.641522   \n",
       "std        12.080519       1.088911        0.0       0.0       2.029226   \n",
       "min      -399.666667       0.250000       80.0    5148.0    -109.002508   \n",
       "25%         1.000000       0.250000       80.0    5148.0     -46.577054   \n",
       "50%         2.333333       0.660000       80.0    5148.0     -46.552598   \n",
       "75%         3.666667       1.000000       80.0    5148.0     -46.489940   \n",
       "max      1000.333333      20.000000       80.0    5148.0     -46.308598   \n",
       "\n",
       "                   X  num_deliver_per_week  num_visit_per_week  \n",
       "count  254051.000000         254051.000000            254051.0  \n",
       "mean     -107.777588              3.164680                 1.0  \n",
       "std         2.030981              0.392777                 0.0  \n",
       "min      -108.620920              2.000000                 1.0  \n",
       "25%      -107.930286              3.000000                 1.0  \n",
       "50%      -107.892716              3.000000                 1.0  \n",
       "75%      -107.856730              3.000000                 1.0  \n",
       "max       -46.442785              6.000000                 1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['customer_id','product_id','order_id']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos un analisis por cada variable:\n",
    "\n",
    "* **purchase date**: Se observa una cierta estacionalidad con tendencia en la cantidad de transacciones realizadas por fecha\n",
    "\n",
    "* **items**: La cantidad de items se ve concentrada entre 1 y 3 items sin embargo hay claras se√±ales de outliers que se pueden ver tanto en el grafico de distribuciones como en los quartiles\n",
    "\n",
    "* **brand**: La gran mayoria de transacciones se concentran en 6 marcas de un total de 21 marcas\n",
    "\n",
    "* **category**: Todas las transacciones pertenecen a la categoria de bebidas carbonatadas, por tanto esta no es una variable relevante para generar predicciones posteriormente. \n",
    "\n",
    "* **sub category**: Solo tenemos 2 subgcaegorias y la gran mayoria de transacciones pertenecen a gaseosas, aguas saborizadas solo representan el 0,17% de las transacciones.\n",
    "\n",
    "* **segment**: Los segmentos se ven liderados por la categoria medium, luego el resta de categorias son relativamente uniformes en distribucion. \n",
    "\n",
    "* **package**: Tenemos 3 categorias y practicamente todas las transacciones estan concentradas en botellas y latas, Keg solo representa el 0.3% de las transacciones.\n",
    "\n",
    "* **size**: La gran mayoria de las transacciones estan concentradas en el rango [0.25,1], pero tal como se puede ver en los rangos quartilicos y en el grafico de distribucion, hay outliers que no nos permiten obsvervar correctamente la distribucion. Sin embargo a pesar de ser una variable numerica, solo existen 7 tipos de tama√±os lo que nos invita a tratar esta variable como una categorica.\n",
    "\n",
    "* **region id**: Todas las transacciones corresponden a la misma region, que es la region 80. Es por esta razon que para efecto de las predicciones no es una variable relevante. \n",
    "\n",
    "* **zone id**: Al igual que la region, todas las transacciones son realizadas en la misma zona (5148). No es una variable relevante para realizar predicciones. \n",
    "\n",
    "* **customer type**: Tenemos 7 categorias, luego gran parte de las transacciones corresponden a abarrotes. \n",
    "\n",
    "* **X,Y**: Referentes a las coordenadas de la ubicacion de la tienda. Todas las tiendas parecen concentrarse en una region determinada ([-46.5,-46.3],[-108.6,-107.8]), por la naturaleza de los outliers en cada columna, de la impresion de que los outliers son errores de typeo donde las coordenadas X e Y estan invertidas (Posteriormente podemos hacer un analisis para confirmar esta hipotesis).\n",
    "\n",
    "* **num deliver per week**: El numero de entregas por semana se encuentra en el rango [2,6], donde la mayoria de los clientes asociadas a las transacciones reciben 3 entregas\n",
    "\n",
    "* **num visit per week**: Todos los clientes asociados a las transacciones tienen 1 visita semanal a la fuerza de venta, por tanto no es una varible relevante a la hora de hacer predicciones.\n",
    "\n",
    "Una vez hecho este analisis procedemos a eliminar las variables que no nos resultan relevantes a la hora de hacer predicciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['category','region_id','zone_id','num_visit_per_week'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå EDA [0.5 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExbHZ6aGdkd21tYTI3cW8zYWhyYW5wdGlyb2s3MmRzeTV0dzQ1NWlueiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3k1hJubTtOAKPKx4k3/giphy.gif\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci√≥n, se debe realizar un an√°lisis exploratorio de los datos para comprender su estructura, detectar posibles problemas y obtener informaci√≥n relevante para el entrenamiento de los modelos. La idea es que puedan detectar **patrones en los datos** que les permitan resolver el problema con mayor facilidad.\n",
    "\n",
    "Se deben responder preguntas a partir de lo que puedan visualizar/obtener, por ejemplo:\n",
    "\n",
    "- Clientes y productos\n",
    "\n",
    "    - ¬øCu√°ntos clientes √∫nicos hay en el dataset?\n",
    "\n",
    "    - ¬øCu√°ntos productos √∫nicos se encuentran en los datos?\n",
    "\n",
    "- Periodo y frecuencia\n",
    "\n",
    "    - ¬øDe qu√© periodo es la informaci√≥n disponible?\n",
    "\n",
    "    - ¬øCu√°l es la frecuencia de los registros (diaria, semanal, mensual, etc.)?\n",
    "\n",
    "- Calidad de los datos\n",
    "\n",
    "    - ¬øExisten valores nulos en el dataset? ¬øCu√°ntos? ¬øC√≥mo se pueden tratar?\n",
    "\n",
    "    - ¬øHay datos raros, como cantidades negativas o inconsistencias? Genere tests de validaci√≥n para identificar estos problemas.\n",
    "\n",
    "- Patrones de compra\n",
    "\n",
    "    - ¬øCu√°ntos productos compra en promedio cada cliente semana a semana?\n",
    "\n",
    "    - ¬øCu√°ntas transacciones ha realizado cada cliente?\n",
    "\n",
    "    - ¬øCu√°l es el periodo de recompra promedio de cada SKU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clientes, productos y periodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cells": {
          "align": "left",
          "fill": {
           "color": "lavender"
          },
          "font": {
           "size": 13
          },
          "values": [
           [
            "Clientes √∫nicos",
            "Productos √∫nicos",
            "Per√≠odo de registros"
           ],
           [
            1490,
            114,
            "01/01/2024 - 31/12/2024"
           ]
          ]
         },
         "header": {
          "align": "left",
          "fill": {
           "color": "paleturquoise"
          },
          "font": {
           "color": "black",
           "size": 14
          },
          "values": [
           "M√©trica",
           "Valor"
          ]
         },
         "type": "table"
        }
       ],
       "layout": {
        "height": 300,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Resumen de los datos"
        },
        "width": 600
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clientes_unicos = df['customer_id'].nunique()\n",
    "productos_unicos = df['product_id'].nunique()\n",
    "fecha_min = df['purchase_date'].min().strftime('%d/%m/%Y') #Esto es para que no salga la hora en la tabla\n",
    "fecha_max = df['purchase_date'].max().strftime('%d/%m/%Y')\n",
    "periodo = f\"{fecha_min} - {fecha_max}\"\n",
    "\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=[\"M√©trica\", \"Valor\"],\n",
    "        fill_color='paleturquoise',\n",
    "        align='left',\n",
    "        font=dict(size=14, color='black')\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[\n",
    "            [\"Clientes √∫nicos\", \"Productos √∫nicos\", \"Per√≠odo de registros\"],\n",
    "            [clientes_unicos, productos_unicos, periodo]\n",
    "        ],\n",
    "        fill_color='lavender',\n",
    "        align='left',\n",
    "        font=dict(size=13)\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(title=\"Resumen de los datos\", width=600, height=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la tabla anterior podemos ver en primer lugar que no todos los clientes en nuestra base de datos hacen transacciones y que no todos los productos en nuestro catalogo son transados, pues en nuestra base de datos hay 1569 clientes y 971 productos. Luego el periodo de transacciones observado es de 1 a√±o. En cuanto a lo anterior es razonable querer a√±adir estos clientes - productos pues estos productos - clientes pueden compartir muchas similitudes con los que efectivamente se ve en el dateset. Esto generar√≠a que el modelo asocie esos productos a no compra aun cuando si lo pueden ser. Y como la gran mayoria de los productos no son transados las probabilidades disminuiran mucho. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupaciones por frecuencia\n",
    "por_dia = df.groupby(df['purchase_date'].dt.date).size()\n",
    "por_semana = df.groupby(pd.Grouper(key='purchase_date', freq='W')).size()\n",
    "por_mes = df.groupby(pd.Grouper(key='purchase_date', freq='M')).size()\n",
    "\n",
    "# los 3 subplots\n",
    "fig = make_subplots(rows=3, cols=1, shared_xaxes=False,\n",
    "                    subplot_titles=(\"Frecuencia diaria\", \"Frecuencia semanal\", \"Frecuencia mensual\"))\n",
    "\n",
    "# Histograma diario\n",
    "fig.add_trace(go.Bar(x=por_dia.index, y=por_dia.values, name='Diario'),\n",
    "              row=1, col=1)\n",
    "\n",
    "# Histograma semanal\n",
    "fig.add_trace(go.Bar(x=por_semana.index, y=por_semana.values, name='Semanal'),\n",
    "              row=2, col=1)\n",
    "\n",
    "# Histograma mensual\n",
    "fig.add_trace(go.Bar(x=por_mes.index, y=por_mes.values, name='Mensual'),\n",
    "              row=3, col=1)\n",
    "\n",
    "fig.update_layout(height=900, width=1000, title_text=\"Frecuencia de registros por d√≠a, semana y mes\")\n",
    "fig.update_xaxes(title_text=\"Fecha\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Cantidad de registros\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Cantidad de registros\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Cantidad de registros\", row=3, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que podemos analizar del grafico anterior es que hay estacionalidad semanal, es decir hay dias de la semana en particular donde probablemente se hacen los pedidos, luego cuando vemos la frecuencia a nivel de semana y mes es claro ver que hay periodos de tiempo en particular (Junio Y Agosto) donde las transacciones caen bastante, y periodos previos a navidad - a√±o nuevo donde las transacciones aumentan mucho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calidad de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos en la seccion anterior no hay valores faltantes, sin embargo si hay anomalias en los datos, en *items* y *size* hay valores atipicos mientras que en las coordenadas X e Y puden haber errores de typeo u outliers, en el caso de *items* y *size* podemos hacer una normalizacion, estandarizacion de los datos o eliminarlos. Mientras que para las coordenadas X e Y podemos hacer un analisis de aquellas tiendas que tienen valores atipicos para ver a que cliente en particular pertenencen y discernir si corresponden a ubicaciones reales o errores de typeo. Finalmente mencionar que en *items* no solo tenemos valores atipicos, si no que tambien negativos, esto no es tan extra√±o pues los valores negativos pueden corresponder a devoluciones, este es un punto sumamente importante pues el objetivo del proyecto es predecir probabilidades de compra. ¬øNos servir√° un cliente que compra 100 y devuelve 90? Mas aun, ¬øQueremos ofrecerle 100 a alguien que nos devolver√° 90? Quizas lo mejor ser√≠a que ese cliente se considere como uno que simplemente compra 10. Lo que sugiere este razonamiento es agrupar las compras y devoluciones de un mismo producto para cada cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos en la seccion anterior no tenemos valores faltantes en nuestro dataset, sin embargo no olvidemos que el objetivo de este proyecto es hacer un sistema de recomendacion basado en probabilidades de compra, cual es nuestra variable a predecir y? Son nuestros registros, en efecto cada registro corresponde a una compra y los registros que no corresponden a compras son los registros que no existen en nuestro datset. Como hemos visto en la parte anterior tenemos 1490 tiendas, 114 clientes y 366 dias. Como nosotros queremos estudiar la probabilidad de que un cliente compre un determinado producto en una fecha dada, necesitamos la combinacion de cliente, producto, dia para cada combinacion de estos valores. Esto nos da un total de 62.168.760 registros y sin embargo tenemos tan solo 254.051. Esto quiere decir que tenemos 61.914.709 registros en donde no hay compras. Si hacemos la ampliacion del dataset estos registros donde no hay compras tendrian en sus columnas *order_id, items* valores nulos. Que hacemos con estos valores nulos? A la columna items le asignamos el valor 0, pues decir que no existi√≥ la transaccion es equivalente a decir que se transaron 0 items. Por otra parte podemos asigar un unico order_id a todos los registros inexistentes. Finalmente agregar que queremos hacer predicciones semanales, por tanto se deben agregar los datos a esta temporalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'product_id', 'order_id', 'purchase_date', 'items',\n",
       "       'brand', 'sub_category', 'segment', 'package', 'size', 'customer_type',\n",
       "       'Y', 'X', 'num_deliver_per_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  variable de semana (a√±o-semana) por si despues entregan otro a√±o\n",
    "transacciones['year_week'] = transacciones['purchase_date'].dt.strftime('%Y-%U')  # Semana del a√±o\n",
    "\n",
    "# agregaci√≥n semanal\n",
    "cols_to_keep = ['customer_id', 'product_id', 'year_week']\n",
    "\n",
    "\n",
    "weekly_df = transacciones.groupby(cols_to_keep).agg({\n",
    "    'items': 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "# los valores √∫nicos observados en las transacciones y que por tanto hay que sacar de df y no de las BD originales\n",
    "customers = df['customer_id'].unique()\n",
    "products = df['product_id'].unique()\n",
    "weeks = df['purchase_date'].dt.strftime('%Y-%U').unique()\n",
    "\n",
    "# combinaciones posibles cliente-producto-semana\n",
    "full_index = pd.MultiIndex.from_product(\n",
    "    [customers, products, weeks],\n",
    "    names=['customer_id', 'product_id', 'year_week']\n",
    ")\n",
    "full_df = pd.DataFrame(index=full_index).reset_index()\n",
    "\n",
    "# se une con el dataset agregado\n",
    "df_completo = pd.merge(\n",
    "    full_df,\n",
    "    weekly_df,\n",
    "    on=['customer_id', 'product_id', 'year_week'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# se completa con las variables de clientes y productos\n",
    "df_completo = df_completo.merge(clientes, on='customer_id', how='left')\n",
    "df_completo = df_completo.merge(productos, on='product_id', how='left')\n",
    "\n",
    "df_completo['items'] = df_completo['items'].fillna(0)\n",
    "\n",
    "# Nuestra variable de interes, aqui en particular puede que haya existido un registro y que tenga items 0\n",
    "# aqui lo estamos considerando como no compra\n",
    "df_completo['y'] = (df_completo['items'] > 0).astype(int)\n",
    "\n",
    "#Finalemente esto es para definir la variable temporal como una de tipo datetime y no un string\n",
    "df_completo['year_week'] = pd.to_datetime(df_completo['year_week'] + '-1', format='%Y-%U-%w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9002580 entries, 0 to 9002579\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Dtype         \n",
      "---  ------                -----         \n",
      " 0   customer_id           int64         \n",
      " 1   product_id            int64         \n",
      " 2   year_week             datetime64[ns]\n",
      " 3   items                 float64       \n",
      " 4   region_id             int64         \n",
      " 5   zone_id               int64         \n",
      " 6   customer_type         object        \n",
      " 7   Y                     float64       \n",
      " 8   X                     float64       \n",
      " 9   num_deliver_per_week  int64         \n",
      " 10  num_visit_per_week    int64         \n",
      " 11  brand                 object        \n",
      " 12  category              object        \n",
      " 13  sub_category          object        \n",
      " 14  segment               object        \n",
      " 15  package               object        \n",
      " 16  size                  float64       \n",
      " 17  y                     int32         \n",
      "dtypes: datetime64[ns](1), float64(4), int32(1), int64(6), object(6)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patrones de compra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# promedio de productos por semana por cliente\n",
    "promedio_productos_semana = (\n",
    "    df_completo.groupby('customer_id')['items'].mean().reset_index(name='prom_produc_semana')\n",
    ")\n",
    "\n",
    "df_promedio_productos = promedio_productos_semana.reset_index()\n",
    "\n",
    "# transacciones por cliente\n",
    "transacciones = df[['customer_id', 'order_id']].drop_duplicates()\n",
    "transacciones_por_cliente = (\n",
    "    transacciones.groupby('customer_id').size().reset_index(name='transaction_count')\n",
    ")\n",
    "\n",
    "df_transacciones_cliente = transacciones_por_cliente.reset_index()\n",
    "\n",
    "#A√±adimos esta features a nuestro dataframe\n",
    "df_completo = df_completo.merge(promedio_productos_semana, on='customer_id', how='left')\n",
    "df_completo = df_completo.merge(transacciones_por_cliente, on='customer_id', how='left')\n",
    "\n",
    "\n",
    "# la subfigura\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Promedio de productos por semana', 'Transacciones por cliente'),\n",
    ")\n",
    "\n",
    "# Gr√°fico para \"Promedio de productos por semana\"\n",
    "fig.add_trace(go.Bar(\n",
    "    x=df_promedio_productos.index,\n",
    "    y=df_promedio_productos['prom_produc_semana'],\n",
    "    marker=dict(color='skyblue', line=dict(width=2, color='lightblue')),\n",
    "    name='Promedio de productos',\n",
    "), row=1, col=1)\n",
    "\n",
    "# Gr√°fico para \"N√∫mero de transacciones por cliente\"\n",
    "fig.add_trace(go.Bar(\n",
    "    x=df_transacciones_cliente.index, \n",
    "    y=df_transacciones_cliente['transaction_count'], \n",
    "    marker=dict(color='lightcoral', line=dict(width=2, color='lightblue')),\n",
    "    name='Transacciones por cliente',\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Promedio de productos y transacciones por cliente\",\n",
    "    plot_bgcolor='white',  \n",
    "    yaxis_title='Promedio de productos',\n",
    "    xaxis=dict(tickangle=45),\n",
    "    yaxis=dict(title='Promedio de productos'),  \n",
    "    yaxis2=dict(title='N√∫mero de transacciones', \n",
    "                overlaying='y',  \n",
    "                side='right'), \n",
    "    bargap=0.1,  \n",
    "    showlegend=False \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los graficos anteriores se puede ver en primer lugar que la mayoria de los clientes tiene un comportamiento parecido en la cantidad de productos que compran semanalmente, a excepcion de un par de clientes que se pueden estar viendo influenciados por los outliers que vimos en la seccion anterior, luego en cuanto a la cantidad de transacciones realizadas la mayor cantidad de clientes se comportan de manera similar sin embargo se pueden distinguir dos grupos, los que realizan alrededor de 50 transacciones y  los que realizan 100 transacciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "\n",
    "df_sorted = df.sort_values(['product_id', 'purchase_date'])\n",
    "\n",
    "df_sorted['recompra_promedio'] = df_sorted.groupby('product_id')['purchase_date'].diff().dt.days\n",
    "\n",
    "recompra_promedio = df_sorted.groupby('product_id')['recompra_promedio'].mean()\n",
    "\n",
    "#A√±adimos la variable al dataset\n",
    "df_completo = df_completo.merge(recompra_promedio, on='product_id', how='left')\n",
    "\n",
    "recompra_promedio_reset = recompra_promedio.reset_index()\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=1, \n",
    "    subplot_titles=('Recompra promedio por SKU',)\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=recompra_promedio_reset.index, \n",
    "    y=recompra_promedio_reset['recompra_promedio'],\n",
    "    marker=dict(color='lightblue', line=dict(width=2, color='lightblue')),\n",
    "    name='Recompra promedio',\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Recompra promedio por SKU\",\n",
    "    plot_bgcolor='white', \n",
    "    xaxis_title='√çndice de producto',\n",
    "    yaxis_title='Promedio de d√≠as entre compras', \n",
    "    xaxis=dict(tickangle=45),\n",
    "    yaxis=dict(title='Promedio de d√≠as entre compras'),  \n",
    "    bargap=0.1, \n",
    "    showlegend=False \n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este grafico se puede ver que la mayoria de los productos tienen una alta rotacion, a excepcion de un par que no se compran mucho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9002580 entries, 0 to 9002579\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Dtype         \n",
      "---  ------                -----         \n",
      " 0   customer_id           int64         \n",
      " 1   product_id            int64         \n",
      " 2   year_week             datetime64[ns]\n",
      " 3   items                 float64       \n",
      " 4   region_id             int64         \n",
      " 5   zone_id               int64         \n",
      " 6   customer_type         object        \n",
      " 7   Y                     float64       \n",
      " 8   X                     float64       \n",
      " 9   num_deliver_per_week  int64         \n",
      " 10  num_visit_per_week    int64         \n",
      " 11  brand                 object        \n",
      " 12  category              object        \n",
      " 13  sub_category          object        \n",
      " 14  segment               object        \n",
      " 15  package               object        \n",
      " 16  size                  float64       \n",
      " 17  y                     int32         \n",
      " 18  prom_produc_semana    float64       \n",
      " 19  transaction_count     int64         \n",
      " 20  recompra_promedio     float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int32(1), int64(7), object(6)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Holdout [0.25 puntos]\n",
    "\n",
    "Para evaluar correctamente el modelo y garantizar su capacidad de generalizaci√≥n, se deben dividir los datos en tres conjuntos: \n",
    "- `Entrenamiento` : Para ajustar los par√°metros.\n",
    "- `Validaci√≥n`: Para optimizar hiperpar√°metros y seleccionar el mejor modelo.\n",
    "- `Prueba` : Para evaluar el rendimiento final en datos no vistos.\n",
    "\n",
    "üëÄ **Hint**: *Recuerde que los datos tienen una temporalidad que debe considerarse al momento de separarlos, para evitar fugas de informaci√≥n. Es importante justificar la estrategia de partici√≥n elegida y visualizar la distribuci√≥n temporal de los conjuntos generados*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui la estrategia es no usar un train test split aleatorio, pues estariamos mezclando eventos pasados con eventos futuros, por tanto la idea es ordenar por fecha el df y luego dividir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5401548 entries, 6776133 to 5292012\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Dtype         \n",
      "---  ------                -----         \n",
      " 0   customer_id           int64         \n",
      " 1   product_id            int64         \n",
      " 2   year_week             datetime64[ns]\n",
      " 3   items                 float64       \n",
      " 4   region_id             int64         \n",
      " 5   zone_id               int64         \n",
      " 6   customer_type         object        \n",
      " 7   Y                     float64       \n",
      " 8   X                     float64       \n",
      " 9   num_deliver_per_week  int64         \n",
      " 10  num_visit_per_week    int64         \n",
      " 11  brand                 object        \n",
      " 12  category              object        \n",
      " 13  sub_category          object        \n",
      " 14  segment               object        \n",
      " 15  package               object        \n",
      " 16  size                  float64       \n",
      " 17  y                     int32         \n",
      " 18  prom_produc_semana    float64       \n",
      " 19  transaction_count     int64         \n",
      " 20  recompra_promedio     float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int32(1), int64(7), object(6)\n",
      "memory usage: 886.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_completo = df_completo.sort_values('year_week')\n",
    "\n",
    "n = len(df_completo)\n",
    "train_end = int(n * 0.6)\n",
    "val_end = int(n * 0.8)\n",
    "\n",
    "df_train = df_completo.iloc[:train_end]\n",
    "df_val = df_completo.iloc[train_end:val_end]\n",
    "df_test = df_completo.iloc[val_end:]\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_entrenamiento = df_train['year_week'].max().to_pydatetime()\n",
    "fecha_validacion = df_val['year_week'].max().to_pydatetime()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_completo['year_week'],\n",
    "    y=df_completo['items'],\n",
    "    mode='lines',\n",
    "    name='Total',\n",
    "    line=dict(color='blue'),\n",
    "    opacity=0.3\n",
    "))\n",
    "\n",
    "fig.add_shape(\n",
    "    type='line',\n",
    "    x0=fecha_entrenamiento,\n",
    "    y0=0,\n",
    "    x1=fecha_entrenamiento,\n",
    "    y1=df_completo['items'].max(),\n",
    "    line=dict(color='green', dash='dash'),\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=fecha_entrenamiento,\n",
    "    y=df_completo['items'].max(),\n",
    "    text=\"Entrenamiento\",\n",
    "    showarrow=True,\n",
    "    arrowhead=1,\n",
    "    ax=0,\n",
    "    ay=-40\n",
    ")\n",
    "\n",
    "fig.add_shape(\n",
    "    type='line',\n",
    "    x0=fecha_validacion,\n",
    "    y0=0,\n",
    "    x1=fecha_validacion,\n",
    "    y1=df_completo['items'].max(),\n",
    "    line=dict(color='orange', dash='dash'),\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=fecha_validacion,\n",
    "    y=df_completo['items'].max(),\n",
    "    text=\"Validaci√≥n\",\n",
    "    showarrow=True,\n",
    "    arrowhead=1,\n",
    "    ax=0,\n",
    "    ay=-40\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Partici√≥n temporal de los datos\",\n",
    "    xaxis_title=\"Fecha\",\n",
    "    yaxis_title=\"Cantidad de √≠tems\",\n",
    "    template=\"plotly_white\",\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Feature Engineering [0.5 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/CmXZSSC.gif\" width=\"300\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci√≥n, se deben construir pipelines para automatizar el preprocesamiento de los datos, lo cual garantizar√° que el flujo de trabajo sea reproducible y eficiente para esta entrega y las futuras. El objetivo es aplicar una serie de transformaciones en un orden definido para asegurar que los datos est√©n listos para los modelos a entrenar. El pipeline final debe incluir las t√©cnicas de pre-procesamiento que se deben aplicar a los distintos datos (seg√∫n lo que consideren necesario para el problema). Por ejemplo:\n",
    "\n",
    "- **Imputaci√≥n de valores nulos**: Manejo de datos faltantes mediante estrategias adecuadas (media, mediana, moda, interpolaci√≥n, etc.). \n",
    "\n",
    "- **Transformaciones personalizadas**: Uso de ColumnTransformer para aplicar diferentes transformaciones a columnas espec√≠ficas.\n",
    "\n",
    "- **Codificaci√≥n de variables categ√≥ricas**: Convertir datos categ√≥ricos a un formato num√©rico adecuado (One-Hot Encoding, Label Encoding, etc.).\n",
    "\n",
    "- **Discretizaci√≥n de variables**: Conversi√≥n de variables num√©ricas continuas en categor√≠as si son relevantes para el desempe√±o del modelo a entrenar.\n",
    "\n",
    "- **Estandarizaci√≥n o normalizaci√≥n** : Ajustar la escala de los datos para mejorar el rendimiento de los algoritmos sensibles a la magnitud de las variables.\n",
    "\n",
    "- **Eliminaci√≥n o transformaci√≥n de valores at√≠picos**: Identificar y tratar con datos outliers para mejorar la robustez del modelo.\n",
    "\n",
    "- **Nuevas caracter√≠sticas** : Creaci√≥n de variables adicionales que puedan aportar informaci√≥n relevante al modelo.\n",
    "\n",
    "Cada una de estas transformaciones debe ser justificada en funci√≥n de su relevancia para el problema y los datos, y es importante evaluar su impacto en el rendimiento del modelo. Adem√°s, el pipeline debe ser flexible y modular para poder probar diferentes configuraciones de preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purchase Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateParser(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        fecha = pd.to_datetime(X.iloc[:, 0], format='%Y-%U-%w')\n",
    "        return pd.DataFrame({\n",
    "            'week': fecha.dt.isocalendar().week.astype('int'),\n",
    "            'month': fecha.dt.month.astype('int'), #igual a√±adimos el mes\n",
    "            'year': fecha.dt.year.astype('int')\n",
    "        }, index=X.index)\n",
    "\n",
    "    def set_output(self, transform='default'):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos anteriormente si bien esta variable es numerica, es de naturaleza categorica, pues clasifica los bebestibles en 7 tama√±os distintos, para hacer un tratamiento de este podemos crear una clase que transforme esta variable en categorica, para luego pasarla a traves de un encoder. Con la exploracion realizada en la seccion de pre-procesamiento sabemos que hay 7 categorias de tama√±os, sin embargo se pueden resumir en 4: peque√±as : $[0.25,0.31,0.33]$; medianas : $[0.5,0.66]$; grandes: $[1]$; muy grandes: $[20]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricaSize(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col='size'):\n",
    "        self.col = col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        def categorizar(val):\n",
    "            if val in [0.25, 0.31, 0.33]:\n",
    "                return 'peque√±a'\n",
    "            elif val in [0.5, 0.66]:\n",
    "                return 'mediana'\n",
    "            elif val == 1:\n",
    "                return 'grande'\n",
    "            elif val == 20:\n",
    "                return 'muy_grande'\n",
    "\n",
    "\n",
    "        X[self.col] = X[self.col].apply(categorizar).astype('category')\n",
    "        return X\n",
    "    \n",
    "    def set_output(self,transform='default'):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X e Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hagamos el tratamiento de las coordenadas X y Y mencionadas anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([236766, 219231, 165126], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['X'] > -100]['customer_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([236766, 219231, 165126], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Y'] < -50]['customer_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero aqui es observar que los outliers que vimos en la coordenadas X e Y pertenecen a los mismos clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-107.879946])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['customer_id'] == 236766]['Y'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-109.0025078])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['customer_id'] == 219231]['Y'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-107.899346])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['customer_id'] == 165126]['Y'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver todas las tiendas asociadas a esos registros tienen la misma ubicacion, por tanto no podemos ver que existe un ejemplo dentro de esas tiendas donde se vea que las coordenadas estan invertidas. Sin embargo hay algo que si sabemos y es que todas las tiendas se ubican en la misma region y en la misma zona, por tanto debiesen estar en lugares cercanos. Veamos cuanta distancia hay entre los puntos que suponemos que tienen coordenadas invertidas y el resto de los otros puntos para ver si son puntos factibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distancia entre puntos: 6018.06 km\n"
     ]
    }
   ],
   "source": [
    "# Funci√≥n Haversine\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radio de la Tierra en km \n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    \n",
    "    a = np.sin(delta_phi / 2.0)**2 + \\\n",
    "        np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "# Una tienda normal\n",
    "x1, y1 = -107.125965, -46.489646  # X: longitud, Y: latitud\n",
    "\n",
    "# Una tienda con coordenadas supuestamente invertidas\n",
    "x2, y2 = -46.589622, -107.899346\n",
    "\n",
    "dist_km = haversine(y1, x1, y2, x2)\n",
    "print(f\"Distancia entre puntos: {dist_km:.2f} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una distancia de 6000 km es mas que la distancia que hay desde Arica hasta Puerto Willams, por tanto en vista de que sabemos que ambos puntos se encuentran en la misma zona, podemos concluir que los puntos estan invertidos. Creemos una funcion que nos permita tener correctamente las variables y luego veamos como se ven en un plano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invertir_coordenadas(df_completo, x_col='X', y_col='Y'):\n",
    "    df_completo = df_completo.copy()\n",
    "\n",
    "    x_valido = df_completo[x_col].between(-110, -106)\n",
    "    y_valido = df_completo[y_col].between(-47, -45)\n",
    "    fuera_de_rango = ~(x_valido & y_valido)\n",
    "\n",
    "    x_invertido_valido = df_completo[y_col].between(-110, -106)\n",
    "    y_invertido_valido = df_completo[x_col].between(-47, -45)\n",
    "    se_pueden_invertir = fuera_de_rango & x_invertido_valido & y_invertido_valido\n",
    "\n",
    "    df_completo.loc[se_pueden_invertir, [x_col, y_col]] = df_completo.loc[se_pueden_invertir, [y_col, x_col]].values\n",
    "\n",
    "    return df_completo\n",
    "\n",
    "df_completo = invertir_coordenadas(df_completo)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.scatter(df_completo['X'], df_completo['Y'], alpha=0.7, c='green', label='Corregido')\n",
    "plt.title('Despu√©s de invertir')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver de forma mucho mas clara la distribucion de las tiendas en el plano. Ahora la implementacion en una clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertirTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, x_col='X', y_col='Y'):\n",
    "        self.x_col = x_col\n",
    "        self.y_col = y_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        x_valido = X[self.x_col].between(-110, -106)\n",
    "        y_valido = X[self.y_col].between(-47, -45)\n",
    "        fuera_de_rango = ~(x_valido & y_valido)\n",
    "\n",
    "        x_invertido_valido = X[self.y_col].between(-110, -106)\n",
    "        y_invertido_valido = X[self.x_col].between(-47, -45)\n",
    "        se_pueden_invertir = fuera_de_rango & x_invertido_valido & y_invertido_valido\n",
    "\n",
    "        X.loc[se_pueden_invertir, [self.x_col, self.y_col]] = X.loc[se_pueden_invertir, [self.y_col, self.x_col]].values\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def set_output(self,transform='default'):\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visualizado en la seccion de preprocesamiento, la gran cantidad de items se concentra en valores bajos en efecto mas del 75% de las transacciones tienen asociados menos de 4 items. Sin embargo tenemos transacciones con 200, 300 hasta 1000 items, es razonable pensar que estos no son valores reales y que por tanto deben ser eliminados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZScoreFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col='items', threshold=1.96):\n",
    "        self.col = col\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.mean_ = X[self.col].mean()\n",
    "        self.std_ = X[self.col].std()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        z_scores = (X[self.col] - self.mean_) / self.std_\n",
    "        mask = np.abs(z_scores) <= self.threshold\n",
    "        return X[mask].reset_index(drop=True)\n",
    "    \n",
    "    def set_output(self,transform='default'):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brand cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['brand'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ser la marca una variable categorica, para efectos del modelo tendremos que codificar como una dummy cad uno de sus valores (21). Para reducir la dimensionalidad de las marcas podemos hacer un analisis de clustering sobre las marcas y agrupar aquellas que son parecidas. Primero veamos la eleccion de los clusters y luego una implementacion mas formal para incluirla en el pipeline general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnas relevantes\n",
    "df_cluster = df_completo[['brand', 'segment','package','size']].copy()\n",
    "\n",
    "# eliminamos duplicados por producto para evitar sesgo por transacci√≥n\n",
    "df_cluster = df_cluster.drop_duplicates(subset=['brand', 'segment', 'package','size'])\n",
    "\n",
    "# brand\n",
    "agg = df_cluster.groupby('brand').agg({\n",
    "    'size' : 'mean',\n",
    "    'package': lambda x: x.mode()[0],\n",
    "    'segment': lambda x: x.mode()[0],\n",
    "}).reset_index()\n",
    "\n",
    "# One-hot encoding para variables categ√≥ricas\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "encoded = ohe.fit_transform(agg[['segment','package']])\n",
    "encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out(['segment','package']))\n",
    "encoded_df.index = agg.index  # Alinear √≠ndices para concatenaci√≥n\n",
    "\n",
    "# Construcci√≥n del dataset para clustering\n",
    "X = pd.concat([agg[['size']], encoded_df], axis=1)\n",
    "\n",
    "# Clustering con KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "agg['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cluster in agg['cluster'].unique():\n",
    "    plt.scatter(\n",
    "        X_2d[agg['cluster'] == cluster, 0],\n",
    "        X_2d[agg['cluster'] == cluster, 1],\n",
    "        label=f'Cluster {cluster}'\n",
    "    )\n",
    "\n",
    "for i, brand in enumerate(agg['brand']):\n",
    "    plt.text(X_2d[i, 0], X_2d[i, 1], brand, fontsize=8)\n",
    "\n",
    "plt.title(\"Clusters de Marcas (Brand) con `items` incluido\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay un cumulo de tiendas en el sector inferior izquierdo, sumado a peque√±os grupos de tiendas que parecen estar cerca en la esquina superior izquierda, si bien no son clusters claramente definidos tener 3 tiendas relativamente parecidas es mejor que 21 marcas por separado. Ahora podemos hacer la transformacion a traves de una clase para incorporarlo al pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idem a la parte anterior pero en la clase\n",
    "class BrandClusterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=3):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.scaler = StandardScaler()\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=0)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        df = X.copy()\n",
    "\n",
    "        df = df.drop_duplicates(subset=['brand', 'segment', 'size','package'])\n",
    "\n",
    "        # Agrupaci√≥n por brand\n",
    "        agg = df.groupby('brand').agg({\n",
    "            'size' : 'mean',\n",
    "            'package': lambda x: x.mode()[0],\n",
    "            'segment': lambda x: x.mode()[0] if not x.mode().empty else 'otro'\n",
    "        }).reset_index()\n",
    "\n",
    "        self.agg_ = agg.copy()\n",
    "\n",
    "        segment_encoded = self.encoder.fit_transform(agg[['segment','package']])\n",
    "        segment_df = pd.DataFrame(segment_encoded, columns=self.encoder.get_feature_names_out(['segment','package']))\n",
    "        segment_df.index = agg.index\n",
    "\n",
    "        X_cluster = pd.concat([agg[['size']], segment_df], axis=1)\n",
    "\n",
    "        X_scaled = self.scaler.fit_transform(X_cluster)\n",
    "\n",
    "        self.kmeans.fit(X_scaled)\n",
    "\n",
    "        self.brand_to_cluster = dict(zip(agg['brand'], self.kmeans.labels_))\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['brand_cluster'] = X['brand'].map(self.brand_to_cluster)\n",
    "        return X\n",
    "    \n",
    "    def set_output(self, transform='default'):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X e Y cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizamos las variables relacionadas al cliente - tienda para hacer el cluster\n",
    "df_cluster = df_completo[['X', 'Y', 'customer_type', 'num_deliver_per_week', 'num_visit_per_week']].copy()\n",
    "\n",
    "agg = df_cluster.groupby(['X', 'Y']).agg({\n",
    "    'customer_type': lambda x: x.mode()[0] if not x.mode().empty else 'otro',\n",
    "    'num_deliver_per_week': 'mean',\n",
    "    'num_visit_per_week': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "customer_encoded = ohe.fit_transform(agg[['customer_type']])\n",
    "customer_encoded_df = pd.DataFrame(customer_encoded, columns=ohe.get_feature_names_out(['customer_type']))\n",
    "\n",
    "X = pd.concat([\n",
    "    agg[['num_deliver_per_week', 'num_visit_per_week']].reset_index(drop=True),\n",
    "    customer_encoded_df.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Aplicaci√≥n de DBSCAN\n",
    "dbscan = DBSCAN(eps=0.7, min_samples=80)\n",
    "agg['cluster'] = dbscan.fit_predict(X)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cluster in agg['cluster'].unique():\n",
    "    plt.scatter(\n",
    "        X_2d[agg['cluster'] == cluster, 0],\n",
    "        X_2d[agg['cluster'] == cluster, 1],\n",
    "        label=f'Cluster {cluster}'\n",
    "    )\n",
    "\n",
    "for i, (x, y) in enumerate(X_2d):\n",
    "    plt.text(x, y, f'{agg[\"X\"].iloc[i]}, {agg[\"Y\"].iloc[i]}', fontsize=8)\n",
    "\n",
    "plt.title(\"Visualizaci√≥n de Clusters (X, Y, items, size)\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando una tecnica de clustering basada en densidad podemos encontrar 2 clusters mas un par outliers. Ahora la implementacion en una clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lo mismo pero en la clase\n",
    "class XYClusterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, eps=0.7, min_samples=80):\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.dbscan = DBSCAN(eps=self.eps, min_samples=self.min_samples)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        df = X.copy()\n",
    "\n",
    "        agg = df.groupby(['X', 'Y']).agg({\n",
    "            'customer_type': lambda x: x.mode()[0] if not x.mode().empty else 'otro',\n",
    "            'num_deliver_per_week': 'mean',\n",
    "            'num_visit_per_week': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        customer_encoded = self.encoder.fit_transform(agg[['customer_type']])\n",
    "        X_cluster = np.concatenate([\n",
    "            agg[['num_deliver_per_week', 'num_visit_per_week']].values,\n",
    "            customer_encoded\n",
    "        ], axis=1)\n",
    "\n",
    "        self.dbscan.fit(X_cluster)\n",
    "        self.XY_to_cluster = dict(zip(zip(agg['X'], agg['Y']), self.dbscan.labels_))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['XY_cluster'] = X.apply(lambda row: self.XY_to_cluster.get((row['X'], row['Y']), -1), axis=1)\n",
    "        return X\n",
    "\n",
    "    def set_output(self, transform='default'):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PipeLine inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;inv&#x27;, InvertirTransformer()),\n",
       "                (&#x27;brand_cluster&#x27;, BrandClusterTransformer()),\n",
       "                (&#x27;xy_cluster&#x27;, XYClusterTransformer()),\n",
       "                (&#x27;column_transform&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;std&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simple_imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;MinMaxScaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;num_deliver_per_week&#x27;,\n",
       "                                                   &#x27;transaction_count&#x27;,\n",
       "                                                   &#x27;recompra_promedio&#x27;]),\n",
       "                                                 (&#x27;enc&#x27;,\n",
       "                                                  Pipel...\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;package&#x27;, &#x27;customer_type&#x27;,\n",
       "                                                   &#x27;segment&#x27;, &#x27;brand_cluster&#x27;,\n",
       "                                                   &#x27;XY_cluster&#x27;]),\n",
       "                                                 (&#x27;tmp&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Date_Parser&#x27;,\n",
       "                                                                   DateParser())]),\n",
       "                                                  [&#x27;year_week&#x27;]),\n",
       "                                                 (&#x27;con&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Convertir&#x27;,\n",
       "                                                                   CategoricaSize()),\n",
       "                                                                  (&#x27;OneHotEncoder_size&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;size&#x27;])]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;inv&#x27;, InvertirTransformer()),\n",
       "                (&#x27;brand_cluster&#x27;, BrandClusterTransformer()),\n",
       "                (&#x27;xy_cluster&#x27;, XYClusterTransformer()),\n",
       "                (&#x27;column_transform&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;std&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simple_imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;MinMaxScaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;num_deliver_per_week&#x27;,\n",
       "                                                   &#x27;transaction_count&#x27;,\n",
       "                                                   &#x27;recompra_promedio&#x27;]),\n",
       "                                                 (&#x27;enc&#x27;,\n",
       "                                                  Pipel...\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;package&#x27;, &#x27;customer_type&#x27;,\n",
       "                                                   &#x27;segment&#x27;, &#x27;brand_cluster&#x27;,\n",
       "                                                   &#x27;XY_cluster&#x27;]),\n",
       "                                                 (&#x27;tmp&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Date_Parser&#x27;,\n",
       "                                                                   DateParser())]),\n",
       "                                                  [&#x27;year_week&#x27;]),\n",
       "                                                 (&#x27;con&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Convertir&#x27;,\n",
       "                                                                   CategoricaSize()),\n",
       "                                                                  (&#x27;OneHotEncoder_size&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;size&#x27;])]))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">InvertirTransformer</label><div class=\"sk-toggleable__content \"><pre>InvertirTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">BrandClusterTransformer</label><div class=\"sk-toggleable__content \"><pre>BrandClusterTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">XYClusterTransformer</label><div class=\"sk-toggleable__content \"><pre>XYClusterTransformer()</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;column_transform: ColumnTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for column_transform: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;std&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simple_imputer&#x27;,\n",
       "                                                  SimpleImputer()),\n",
       "                                                 (&#x27;MinMaxScaler&#x27;,\n",
       "                                                  MinMaxScaler())]),\n",
       "                                 [&#x27;num_deliver_per_week&#x27;, &#x27;transaction_count&#x27;,\n",
       "                                  &#x27;recompra_promedio&#x27;]),\n",
       "                                (&#x27;enc&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;OneHotEncoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;package&#x27;, &#x27;customer_type&#x27;, &#x27;segment&#x27;,\n",
       "                                  &#x27;brand_cluster&#x27;, &#x27;XY_cluster&#x27;]),\n",
       "                                (&#x27;tmp&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Date_Parser&#x27;,\n",
       "                                                  DateParser())]),\n",
       "                                 [&#x27;year_week&#x27;]),\n",
       "                                (&#x27;con&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Convertir&#x27;,\n",
       "                                                  CategoricaSize()),\n",
       "                                                 (&#x27;OneHotEncoder_size&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;size&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">std</label><div class=\"sk-toggleable__content \"><pre>[&#x27;num_deliver_per_week&#x27;, &#x27;transaction_count&#x27;, &#x27;recompra_promedio&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a></label><div class=\"sk-toggleable__content \"><pre>MinMaxScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">enc</label><div class=\"sk-toggleable__content \"><pre>[&#x27;package&#x27;, &#x27;customer_type&#x27;, &#x27;segment&#x27;, &#x27;brand_cluster&#x27;, &#x27;XY_cluster&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">tmp</label><div class=\"sk-toggleable__content \"><pre>[&#x27;year_week&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">DateParser</label><div class=\"sk-toggleable__content \"><pre>DateParser()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">con</label><div class=\"sk-toggleable__content \"><pre>[&#x27;size&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">CategoricaSize</label><div class=\"sk-toggleable__content \"><pre>CategoricaSize()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('inv', InvertirTransformer()),\n",
       "                ('brand_cluster', BrandClusterTransformer()),\n",
       "                ('xy_cluster', XYClusterTransformer()),\n",
       "                ('column_transform',\n",
       "                 ColumnTransformer(transformers=[('std',\n",
       "                                                  Pipeline(steps=[('simple_imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('MinMaxScaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['num_deliver_per_week',\n",
       "                                                   'transaction_count',\n",
       "                                                   'recompra_promedio']),\n",
       "                                                 ('enc',\n",
       "                                                  Pipel...\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['package', 'customer_type',\n",
       "                                                   'segment', 'brand_cluster',\n",
       "                                                   'XY_cluster']),\n",
       "                                                 ('tmp',\n",
       "                                                  Pipeline(steps=[('Date_Parser',\n",
       "                                                                   DateParser())]),\n",
       "                                                  ['year_week']),\n",
       "                                                 ('con',\n",
       "                                                  Pipeline(steps=[('Convertir',\n",
       "                                                                   CategoricaSize()),\n",
       "                                                                  ('OneHotEncoder_size',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['size'])]))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "lista_stand = ['num_deliver_per_week','transaction_count','recompra_promedio']\n",
    "lista_categoricas = ['package', 'customer_type', 'segment','brand_cluster','XY_cluster']\n",
    "lista_temporales = ['year_week']\n",
    "lista_invertir = ['X','Y']\n",
    "lista_convertir = ['size']\n",
    "\n",
    "\n",
    "trans_stand = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='mean')), \n",
    "    ('MinMaxScaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "trans_categoricas = Pipeline([\n",
    "    ('OneHotEncoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "trans_temporales = Pipeline([\n",
    "    ('Date_Parser', DateParser())\n",
    "])\n",
    "\n",
    "trans_invertir = Pipeline([\n",
    "    ('Invertir', InvertirTransformer())\n",
    "])\n",
    "\n",
    "trans_convertir = Pipeline([\n",
    "    ('Convertir',CategoricaSize()),\n",
    "    ('OneHotEncoder_size', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocesamiento = Pipeline([\n",
    "    ('inv', InvertirTransformer()),\n",
    "    ('brand_cluster', BrandClusterTransformer(n_clusters=3)),\n",
    "    ('xy_cluster', XYClusterTransformer()),\n",
    "    ('column_transform', ColumnTransformer([\n",
    "        ('std', trans_stand, lista_stand),\n",
    "        ('enc', trans_categoricas, lista_categoricas),\n",
    "        ('tmp', trans_temporales, lista_temporales),\n",
    "        ('con', trans_convertir, lista_convertir)\n",
    "    ]))\n",
    "])  \n",
    "\n",
    "preprocesamiento.set_output(transform='pandas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naach\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformado = preprocesamiento.fit_transform(df_completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9002580 entries, 6776133 to 9002579\n",
      "Data columns (total 30 columns):\n",
      " #   Column                                     Dtype  \n",
      "---  ------                                     -----  \n",
      " 0   std__num_deliver_per_week                  float64\n",
      " 1   std__transaction_count                     float64\n",
      " 2   std__recompra_promedio                     float64\n",
      " 3   enc__package_BOTELLA                       float64\n",
      " 4   enc__package_KEG                           float64\n",
      " 5   enc__package_LATA                          float64\n",
      " 6   enc__customer_type_ABARROTES               float64\n",
      " 7   enc__customer_type_CANAL FRIO              float64\n",
      " 8   enc__customer_type_MAYORISTA               float64\n",
      " 9   enc__customer_type_MINIMARKET              float64\n",
      " 10  enc__customer_type_RESTAURANT              float64\n",
      " 11  enc__customer_type_SUPERMERCADO            float64\n",
      " 12  enc__customer_type_TIENDA DE CONVENIENCIA  float64\n",
      " 13  enc__segment_HIGH                          float64\n",
      " 14  enc__segment_LOW                           float64\n",
      " 15  enc__segment_MEDIUM                        float64\n",
      " 16  enc__segment_PREMIUM                       float64\n",
      " 17  enc__brand_cluster_0                       float64\n",
      " 18  enc__brand_cluster_1                       float64\n",
      " 19  enc__brand_cluster_2                       float64\n",
      " 20  enc__XY_cluster_-1                         float64\n",
      " 21  enc__XY_cluster_0                          float64\n",
      " 22  enc__XY_cluster_1                          float64\n",
      " 23  tmp__week                                  int32  \n",
      " 24  tmp__month                                 int32  \n",
      " 25  tmp__year                                  int32  \n",
      " 26  con__size_grande                           float64\n",
      " 27  con__size_mediana                          float64\n",
      " 28  con__size_muy_grande                       float64\n",
      " 29  con__size_peque√±a                          float64\n",
      "dtypes: float64(27), int32(3)\n",
      "memory usage: 2.0 GB\n"
     ]
    }
   ],
   "source": [
    "df_transformado.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Baseline [0.25 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExN3lzeGFqZmU3NzJrZHllNjRmaHVzczJpZ29rdHdlMzVpZnQwNXo1diZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/qAtZM2gvjWhPjmclZE/giphy.gif\" width=\"300\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci√≥n se debe construir el modelo m√°s sencillo posible que pueda resolver el problema planteado, conocido como **Modelo baseline**. Su prop√≥sito es servir como referencia para comparar el rendimiento de los modelos m√°s avanzados desarrollados en etapas posteriores.  \n",
    "\n",
    "Pasos requeridos:  \n",
    "- Implemente, entrene y eval√∫e un modelo b√°sico utilizando un pipeline.  \n",
    "- Aseg√∫rese de incluir en el pipeline las transformaciones del preprocesamiento realizadas previamente junto con un clasificador b√°sico.  \n",
    "- Eval√∫e el modelo y presente el informe de m√©tricas utilizando **`classification_report`**.  \n",
    "\n",
    "Documente claramente c√≥mo se cre√≥ el modelo, las decisiones tomadas y los resultados obtenidos. Este modelo ser√° la base comparativa en las secciones posteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se comienzan separando los df en X e y, seg√∫n cada caso (train, val y test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtiene X e y en train, test y val\n",
    "y_train = df_train['y']\n",
    "X_train = df_train.drop(columns=['y'])\n",
    "\n",
    "y_val = df_val['y']\n",
    "X_val = df_val.drop(columns=['y'])\n",
    "\n",
    "y_test = df_test['y']\n",
    "X_test = df_test.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Luego, en base a el conocimiento adquirido en laboratorios pasados y sabiendo que Dummy Classifier es un modelo de clasificaci√≥n simple que genera predicciones en base a la estrategia definida, pero sin aprender de los datos, se elige como modelo baseline. En particular, la estrategia a seguir es 'stratified' ya que los datos se encuentran desbalanceados, por lo que esto respetar√° este comportamiento, observando as√≠ un modelo simple, el cual idealmente debe ser superado por modelos mucho m√°s complejos en donde en el entrenamiento si aprenden de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naach\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocesamiento&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;inv&#x27;, InvertirTransformer()),\n",
       "                                 (&#x27;brand_cluster&#x27;, BrandClusterTransformer()),\n",
       "                                 (&#x27;xy_cluster&#x27;, XYClusterTransformer()),\n",
       "                                 (&#x27;column_transform&#x27;,\n",
       "                                  ColumnTransformer(transformers=[(&#x27;std&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;simple_imputer&#x27;,\n",
       "                                                                                    SimpleImputer()),\n",
       "                                                                                   (&#x27;MinMaxScaler&#x27;,\n",
       "                                                                                    MinMaxScaler())]),\n",
       "                                                                   [&#x27;num_deliver_per_week&#x27;,\n",
       "                                                                    &#x27;transaction_count...\n",
       "                                                                                                  sparse_output=False))]),\n",
       "                                                                   [&#x27;package&#x27;,\n",
       "                                                                    &#x27;customer_type&#x27;,\n",
       "                                                                    &#x27;segment&#x27;,\n",
       "                                                                    &#x27;brand_cluster&#x27;,\n",
       "                                                                    &#x27;XY_cluster&#x27;]),\n",
       "                                                                  (&#x27;tmp&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;Date_Parser&#x27;,\n",
       "                                                                                    DateParser())]),\n",
       "                                                                   [&#x27;year_week&#x27;]),\n",
       "                                                                  (&#x27;con&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;Convertir&#x27;,\n",
       "                                                                                    CategoricaSize()),\n",
       "                                                                                   (&#x27;OneHotEncoder_size&#x27;,\n",
       "                                                                                    OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                                  sparse_output=False))]),\n",
       "                                                                   [&#x27;size&#x27;])]))])),\n",
       "                (&#x27;dummy&#x27;, DummyClassifier(strategy=&#x27;stratified&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocesamiento&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;inv&#x27;, InvertirTransformer()),\n",
       "                                 (&#x27;brand_cluster&#x27;, BrandClusterTransformer()),\n",
       "                                 (&#x27;xy_cluster&#x27;, XYClusterTransformer()),\n",
       "                                 (&#x27;column_transform&#x27;,\n",
       "                                  ColumnTransformer(transformers=[(&#x27;std&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;simple_imputer&#x27;,\n",
       "                                                                                    SimpleImputer()),\n",
       "                                                                                   (&#x27;MinMaxScaler&#x27;,\n",
       "                                                                                    MinMaxScaler())]),\n",
       "                                                                   [&#x27;num_deliver_per_week&#x27;,\n",
       "                                                                    &#x27;transaction_count...\n",
       "                                                                                                  sparse_output=False))]),\n",
       "                                                                   [&#x27;package&#x27;,\n",
       "                                                                    &#x27;customer_type&#x27;,\n",
       "                                                                    &#x27;segment&#x27;,\n",
       "                                                                    &#x27;brand_cluster&#x27;,\n",
       "                                                                    &#x27;XY_cluster&#x27;]),\n",
       "                                                                  (&#x27;tmp&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;Date_Parser&#x27;,\n",
       "                                                                                    DateParser())]),\n",
       "                                                                   [&#x27;year_week&#x27;]),\n",
       "                                                                  (&#x27;con&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;Convertir&#x27;,\n",
       "                                                                                    CategoricaSize()),\n",
       "                                                                                   (&#x27;OneHotEncoder_size&#x27;,\n",
       "                                                                                    OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                                  sparse_output=False))]),\n",
       "                                                                   [&#x27;size&#x27;])]))])),\n",
       "                (&#x27;dummy&#x27;, DummyClassifier(strategy=&#x27;stratified&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocesamiento: Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for preprocesamiento: Pipeline</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;inv&#x27;, InvertirTransformer()),\n",
       "                (&#x27;brand_cluster&#x27;, BrandClusterTransformer()),\n",
       "                (&#x27;xy_cluster&#x27;, XYClusterTransformer()),\n",
       "                (&#x27;column_transform&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;std&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simple_imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;MinMaxScaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;num_deliver_per_week&#x27;,\n",
       "                                                   &#x27;transaction_count&#x27;,\n",
       "                                                   &#x27;recompra_promedio&#x27;]),\n",
       "                                                 (&#x27;enc&#x27;,\n",
       "                                                  Pipel...\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;package&#x27;, &#x27;customer_type&#x27;,\n",
       "                                                   &#x27;segment&#x27;, &#x27;brand_cluster&#x27;,\n",
       "                                                   &#x27;XY_cluster&#x27;]),\n",
       "                                                 (&#x27;tmp&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Date_Parser&#x27;,\n",
       "                                                                   DateParser())]),\n",
       "                                                  [&#x27;year_week&#x27;]),\n",
       "                                                 (&#x27;con&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Convertir&#x27;,\n",
       "                                                                   CategoricaSize()),\n",
       "                                                                  (&#x27;OneHotEncoder_size&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;size&#x27;])]))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">InvertirTransformer</label><div class=\"sk-toggleable__content fitted\"><pre>InvertirTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">BrandClusterTransformer</label><div class=\"sk-toggleable__content fitted\"><pre>BrandClusterTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XYClusterTransformer</label><div class=\"sk-toggleable__content fitted\"><pre>XYClusterTransformer()</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;column_transform: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for column_transform: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;std&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simple_imputer&#x27;,\n",
       "                                                  SimpleImputer()),\n",
       "                                                 (&#x27;MinMaxScaler&#x27;,\n",
       "                                                  MinMaxScaler())]),\n",
       "                                 [&#x27;num_deliver_per_week&#x27;, &#x27;transaction_count&#x27;,\n",
       "                                  &#x27;recompra_promedio&#x27;]),\n",
       "                                (&#x27;enc&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;OneHotEncoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;package&#x27;, &#x27;customer_type&#x27;, &#x27;segment&#x27;,\n",
       "                                  &#x27;brand_cluster&#x27;, &#x27;XY_cluster&#x27;]),\n",
       "                                (&#x27;tmp&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Date_Parser&#x27;,\n",
       "                                                  DateParser())]),\n",
       "                                 [&#x27;year_week&#x27;]),\n",
       "                                (&#x27;con&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Convertir&#x27;,\n",
       "                                                  CategoricaSize()),\n",
       "                                                 (&#x27;OneHotEncoder_size&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;size&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">std</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;num_deliver_per_week&#x27;, &#x27;transaction_count&#x27;, &#x27;recompra_promedio&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">enc</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;package&#x27;, &#x27;customer_type&#x27;, &#x27;segment&#x27;, &#x27;brand_cluster&#x27;, &#x27;XY_cluster&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">tmp</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;year_week&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">DateParser</label><div class=\"sk-toggleable__content fitted\"><pre>DateParser()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">con</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;size&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CategoricaSize</label><div class=\"sk-toggleable__content fitted\"><pre>CategoricaSize()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DummyClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.dummy.DummyClassifier.html\">?<span>Documentation for DummyClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DummyClassifier(strategy=&#x27;stratified&#x27;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocesamiento',\n",
       "                 Pipeline(steps=[('inv', InvertirTransformer()),\n",
       "                                 ('brand_cluster', BrandClusterTransformer()),\n",
       "                                 ('xy_cluster', XYClusterTransformer()),\n",
       "                                 ('column_transform',\n",
       "                                  ColumnTransformer(transformers=[('std',\n",
       "                                                                   Pipeline(steps=[('simple_imputer',\n",
       "                                                                                    SimpleImputer()),\n",
       "                                                                                   ('MinMaxScaler',\n",
       "                                                                                    MinMaxScaler())]),\n",
       "                                                                   ['num_deliver_per_week',\n",
       "                                                                    'transaction_count...\n",
       "                                                                                                  sparse_output=False))]),\n",
       "                                                                   ['package',\n",
       "                                                                    'customer_type',\n",
       "                                                                    'segment',\n",
       "                                                                    'brand_cluster',\n",
       "                                                                    'XY_cluster']),\n",
       "                                                                  ('tmp',\n",
       "                                                                   Pipeline(steps=[('Date_Parser',\n",
       "                                                                                    DateParser())]),\n",
       "                                                                   ['year_week']),\n",
       "                                                                  ('con',\n",
       "                                                                   Pipeline(steps=[('Convertir',\n",
       "                                                                                    CategoricaSize()),\n",
       "                                                                                   ('OneHotEncoder_size',\n",
       "                                                                                    OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                  sparse_output=False))]),\n",
       "                                                                   ['size'])]))])),\n",
       "                ('dummy', DummyClassifier(strategy='stratified'))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Se construye el baseline \n",
    "# Se juntan los pasos en un pipeline y se entrena\n",
    "pipeline_dummy = Pipeline([('preprocesamiento', preprocesamiento),\n",
    "                     ('dummy', DummyClassifier(strategy='stratified'))])\n",
    "\n",
    "pipeline_dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A continuaci√≥n, se obtiene la predicci√≥n del modelo a partir de y_test, obteniendo un reporte del desempe√±o del modelo del baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de desempe√±o del modelo dummy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98   1749357\n",
      "           1       0.03      0.02      0.02     51159\n",
      "\n",
      "    accuracy                           0.95   1800516\n",
      "   macro avg       0.50      0.50      0.50   1800516\n",
      "weighted avg       0.94      0.95      0.95   1800516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Se obtiene el clasification_report\n",
    "y_pred = pipeline_dummy.predict(X_test)\n",
    "\n",
    "print('Reporte de desempe√±o del modelo dummy: ')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Observando los resultados obtenidos en las distintas m√©tricas y el conocimiento en el desbalance en las clases, este comportamiento se ve reflejado en la clase mayoritaria con m√©tricas bastante cercanas a 1 en todos los casos, pero si se observa la clase minoritaria, las m√©tricas se acercan bastante a cero, por lo que es necesario encontrar modelos que puedan trabajar con este problema. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Elecci√≥n de modelo [0.75 puntos]\n",
    "\n",
    "En esta secci√≥n deben escoger un modelo que se adapte a las necesidades del negocio. Para esto, pruebe al menos 3 modelos y desarrolle los siguientes aspectos para cada uno:\n",
    "\n",
    "- **Estructura y diferencias entre los modelos**: Explicar brevemente cada uno y sus hip√©rpar√°metros de mayor importancia.\n",
    "- **Clasificadores recomendados**:\n",
    "  - `LogisticRegression`\n",
    "  - `KNeighborsClassifier`\n",
    "  - `DecisionTreeClassifier`\n",
    "  - `SVC`\n",
    "  - `RandomForestClassifier`\n",
    "  - `LightGBMClassifier` (del paquete `lightgbm`)\n",
    "  - `XGBClassifier` (del paquete `xgboost`)\n",
    "  - Otro (seg√∫n lo que se estime adecuado)\n",
    "  \n",
    "- **Evaluaci√≥n de resultados**: Se utilizar√° el **`classification_report`** para evaluar el rendimiento de cada modelo, destacando m√©tricas clave como precisi√≥n, recall y F1-score. **Importante: No optimicen hiperpar√°metros, la idea es hacer una selecci√≥n r√°pida del modelo.**\n",
    "\n",
    "**Nota:** Pueden ocupar mas de 1 **instancia** de modelo para resolver el problema (e.g: (modelo_1, grupo_1), (modelo_2, grupo_2), ...).\n",
    "  \n",
    "A continuaci√≥n, se deben responder las siguientes preguntas para evaluar el rendimiento de los modelos entrenados:\n",
    "\n",
    "1. ¬øHay alg√∫n clasificador que supere al modelo baseline?  \n",
    "2. ¬øCu√°l es el mejor clasificador entrenado y por qu√©?  \n",
    "3. ¬øQu√© factores hacen que el mejor clasificador sea superior a los otros?  \n",
    "4. En t√©rminos de `tiempo de entrenamiento`, ¬øQu√© modelo considera m√°s adecuado para experimentar con grillas de optimizaci√≥n?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En base a los modelos propuestos la elecci√≥n de 3 de estos se decidi√≥ por las siguientes razones:\n",
    "    * LogisticRegression: es un modelo que se suele utilizar en clasificaci√≥n binaria y al trabajar con probabilidades, presenta mayor flexibilidad a la hora de clasificar seg√∫n cada clase, pudiendo obtener predicciones m√°s acertadas.\n",
    "    * RandomForestClassifier: es un modelo bastante conocido para entrenar, el cual se conoce por tener un buen desempe√±o en general, debido a el entrenamiento con m√∫ltiples √°rboles, en vez de uno, lo que permite obtener resultados m√°s precisos, pero teniendo en cuenta que este modelo tambi√©n tiene un tiempo alto de entrenamiento.\n",
    "    * XGBoost: teniendo tanto LGBM como XGB se elige el segundo, ya que se obtienen resultados similares en las predicciones, con una leve diferencia en el tiempo de entrenamiento, pero en comparaci√≥n con los elegidos, este es mucho menor. Adem√°s, es un modelo que se encuentra altamente optimizado en tiempo y nivel de predicci√≥n, por lo que es un buen modelo a comparar con los otros 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A continuaci√≥n, se explican brevemente los modelos y sus hiperpar√°metros m√°s importantes:\n",
    "    * LogisticRegression:\n",
    "        * Descripci√≥n: es un modelo que se utiliza en clasificaci√≥n para predecir de manera binaria (la mayor√≠a de las veces) la probabilidad de que una instancia sea parte de una clase o no, entregando un 1 si la probabilidad supera cierta probabilidad de pertenencia o un 0 en caso contrario.\n",
    "        * Hiperpar√°metros: \n",
    "            - penalty: penalizaci√≥n que se aplicar√° al modelo\n",
    "            - C: inverso de la regularizaci√≥n que se aplicar√° en el modelo para penalizar complejidad\n",
    "            - solver: algoritmo que se utilizar√° para optimizar el problema\n",
    "            - mas_iter: n√∫mero m√°ximo de iteraciones para que los solver convergan\n",
    "    * RandomForestClassifier:\n",
    "        * Descripci√≥n: es un modelo que utiliza un conjunto de √°rboles en diferentes subconjuntos para mejorar la precision en la clasificaci√≥n, utilizando el promedio de los resultados obtenidos.\n",
    "        * Hiperpar√°metros: \n",
    "            - n_estimator: n√∫mero de √°rboles a utilizar en el modelo\n",
    "            - max_depth: profundidad m√°xima a la que llegar√°n los √°rboles\n",
    "            - min_samples_split: el n√∫mero m√≠nimo de muestras para que se divida un nodo interno\n",
    "            - max_features: el n√∫mero m√°ximo de features a considerar a la hora de hacer cada divisi√≥n\n",
    "\n",
    "    * XGBoostClassifier: \n",
    "        * Descripci√≥n: es un modelo de clasificaci√≥n basado en gradient boosting que se encuentra altamente optimizado, donde cada nuevo √°rbol que se crea, corrige los errores que presentaron los anteriores\n",
    "        * Hiperpar√°metros:\n",
    "            - n_estimators: n√∫mero de √°rboles a utilizar \n",
    "            - learning_rate: taza de aprendizaje que se aplicar√° en cada ajuste\n",
    "            - max_depth: profundidad m√°xima a la que llegar√°n los √°rboles\n",
    "            - subsample: cantidad de muestras a utilizar en cada √°rbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A continuaci√≥n, se correr√°n los modelos explicados con anterioridad, utilizando los hiperpar√°metros predeterminados por el mismo modelo, para as√≠ poder observar el desempe√±o en su forma m√°s 'b√°sica':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naach\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n",
      "c:\\Users\\naach\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de desempe√±o del modelo Logistic Regression: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naach\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\naach\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99   1749357\n",
      "           1       0.00      0.00      0.00     51159\n",
      "\n",
      "    accuracy                           0.97   1800516\n",
      "   macro avg       0.49      0.50      0.49   1800516\n",
      "weighted avg       0.94      0.97      0.96   1800516\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naach\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se implementa LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Se juntan los pasos en un pipeline y se entrena\n",
    "pipeline_LR = Pipeline([('preprocesamiento', preprocesamiento),\n",
    "                     ('LogisticRegression', LogisticRegression())])\n",
    "\n",
    "pipeline_LR.fit(X_train, y_train)\n",
    "\n",
    "# Se obtiene el clasification_report\n",
    "y_pred_LR = pipeline_LR.predict(X_test)\n",
    "\n",
    "print('Reporte de desempe√±o del modelo Logistic Regression: ')\n",
    "print(classification_report(y_test, y_pred_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seg√∫n las m√©tricas obtenidas para el modelo, se puede notar como la clase mayoritaria se hace presente en las predicciones con valores bastante cercanos, e incluso iguales a 1. Por otro lado, en la clase minoritaria los valores son simplemente 0, por lo que da una alerta del modelo, ya que aunque mejora levemente en las m√©tricas asociadas a la clase 0, en comparaci√≥n con el baseline, cae a 0 en las predicciones de la clase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naach\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de desempe√±o del modelo Random Forest Classifier: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99   1749357\n",
      "           1       0.50      0.21      0.30     51159\n",
      "\n",
      "    accuracy                           0.97   1800516\n",
      "   macro avg       0.74      0.60      0.64   1800516\n",
      "weighted avg       0.96      0.97      0.97   1800516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se implementa RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Se juntan los pasos en un pipeline y se entrena\n",
    "pipeline_RFC= Pipeline([('preprocesamiento', preprocesamiento),\n",
    "                     ('random forest classifier', RandomForestClassifier())])\n",
    "\n",
    "pipeline_RFC.fit(X_train, y_train)\n",
    "\n",
    "# Se obtiene el clasification_report\n",
    "y_pred_RFC= pipeline_RFC.predict(X_test)\n",
    "\n",
    "print('Reporte de desempe√±o del modelo Random Forest Classifier: ')\n",
    "print(classification_report(y_test, y_pred_RFC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seg√∫n las m√©tricas obtenidas para el modelo, se puede notar que ahora hay una mejora considerable en las predicciones de la clase 1, aumentando a incluso valores de precision iguales a 0.5, recall 0.21 y f1-score 0.3. Adem√°s, en comparaci√≥n al baseline, las m√©tricas asociadas a la clase 0, se mantienen iguales, por lo que de manera general, se puede notar una mejora en el modelo random forest en comparaci√≥n al baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naach\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de desempe√±o del modelo XGBoost Classifier: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99   1749357\n",
      "           1       0.65      0.15      0.24     51159\n",
      "\n",
      "    accuracy                           0.97   1800516\n",
      "   macro avg       0.81      0.57      0.61   1800516\n",
      "weighted avg       0.97      0.97      0.97   1800516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se implementa XGBoost classifier\n",
    "from xgboost import XGBClassifier\n",
    "# Se juntan los pasos en un pipeline y se entrena\n",
    "pipeline_XGBC= Pipeline([('preprocesamiento', preprocesamiento),\n",
    "                     ('xgboost classifier', XGBClassifier())])\n",
    "\n",
    "pipeline_XGBC.fit(X_train, y_train)\n",
    "\n",
    "# Se obtiene el clasification_report\n",
    "y_pred_XGBC= pipeline_XGBC.predict(X_test)\n",
    "\n",
    "print('Reporte de desempe√±o del modelo XGBoost Classifier: ')\n",
    "print(classification_report(y_test, y_pred_XGBC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seg√∫n las m√©tricas obtenidas para el modelo, tambi√©n se pueden observar mejorar con respecto al baseline y leves diferencias si se compara con Random Forest, ya que mejora en precision, pero si se observa el f1-score, en el caso de xgboost, este valor cae."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¬øHay alg√∫n clasificador que supere al modelo baseline?  \n",
    "    - Al probar 3 de los modelos propuestos, 2 de ellos superan en la predicci√≥n al modelo baseline, los cuales son Random Forest y XGBoost. \n",
    "    - Se observa principalmente la mejora en la predicci√≥n de la clase 1, aumentando considerablemente los valores cercanos a cero obtenidos en las m√©tricas precision, recall y f1-socre.\n",
    "\n",
    "2. ¬øCu√°l es el mejor clasificador entrenado y por qu√©?  \n",
    "    - Si se observan los clasificadores que superaron al baseline, se puede notar que obtienen un desempe√±o bastante similar, pero como es necesario observar todas las m√©tricas para poder entender el desempe√±o de estos, es que se pone atenci√≥n en f1-score, donde en el caso de Random Forest se obtiene un mejor equilibrio entre las m√©tricas precision y recall. Por lo anterior, se determina que el mejor modelo es Random Forest, pero es importante tener en cuenta que esta leve mejora viene de la mano con un tiempo de entrenamiento mucho mayor.\n",
    "\n",
    "3. ¬øQu√© factores hacen que el mejor clasificador sea superior a los otros?  \n",
    "    - Tal como se mencion√≥ antes, se observa la m√©trica f-score para poder observar el comportamiento de ambas m√©tricas (precision y recall) y as√≠ tomar en consideraci√≥n tanto el comportamiento con los falsos negativos como con los positivos para decidirse por el mejor\n",
    "\n",
    "4. En t√©rminos de `tiempo de entrenamiento`, ¬øQu√© modelo considera m√°s adecuado para experimentar con grillas de optimizaci√≥n?\n",
    "    - En relaci√≥n al tiempo de entrenamiento y considerando que en los modelos que superan al baseline no hay una gran diferencia en sus m√©tricas, se considera m√°s adecuado XGBoost para experimentar con grillas, ya que al estar m√°s optimizado, el tiempo que demora en el entrenamiento es mucho menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Optimizaci√≥n de Hiperpar√°metros [1.0 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExcXJkNzdhYjlneHplaGpsbnVkdzh5dnY3Y2VyaTIzamszdGR1czJ2diZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/2rqEdFfkMzXmo/giphy.gif\" width=\"300\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de su an√°lisis anterior, se debe proceder a optimizar el rendimiento del modelo seleccionado mediante la optimizaci√≥n de sus hiperpar√°metros. Para ello, se espera que implementen `Optuna` para optimizar no solo los hiperpar√°metros del modelo, sino tambi√©n los de los preprocesadores utilizados (por ejemplo, OneHot Encoding, Scalers, etc.).\n",
    "\n",
    "Al desarrollar este proceso, deber√°n responder las siguientes preguntas clave como m√≠nimo:\n",
    "\n",
    "- ¬øQu√© m√©trica decidieron optimizar y por qu√©?\n",
    "\n",
    "- ¬øQu√© hiperpar√°metro tuvo un mayor impacto en el rendimiento de su modelo?\n",
    "\n",
    "- ¬øCu√°nto mejor√≥ el rendimiento del modelo despu√©s de la optimizaci√≥n de hiperpar√°metros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Hiperpar√°metros que se pide optimizar con sus rangos\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 2000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
    "    max_leaves = trial.suggest_int(\"max_leaves\", 0, 100)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.0, 1.0)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.0, 1.0)\n",
    "\n",
    "    # Simple Imputer\n",
    "    strategy = trial.suggest_categorical(\"strategy\", [\"mean\", \"median\", \"most_frequent\", \"constant\"])\n",
    "\n",
    "    # MinMax Scaler\n",
    "    feature_range = trial.suggest_categorical(\"feature_range\", [(0, 1), (-1, 1), (0, 10)])\n",
    "\n",
    "    # One Hot Encoder\n",
    "    min_freq = trial.suggest_float(\"min_frequency\", 0.0, 1.0) \n",
    "\n",
    "    \n",
    "    # Se asignan a los preprocesadores, los hiperparametros a optimizar\n",
    "    trans_stand = Pipeline([\n",
    "        ('simple_imputer', SimpleImputer(strategy=strategy)), \n",
    "        ('MinMaxScaler', MinMaxScaler(feature_range=feature_range))\n",
    "    ])\n",
    "\n",
    "    trans_categoricas = Pipeline([\n",
    "        ('OneHotEncoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore', min_frequency=min_freq))\n",
    "    ])\n",
    "\n",
    "    trans_temporales = Pipeline([\n",
    "        ('Date_Parser', DateParser())\n",
    "    ])\n",
    "\n",
    "    trans_invertir = Pipeline([\n",
    "        ('Invertir', InvertirTransformer())\n",
    "    ])\n",
    "\n",
    "    trans_convertir = Pipeline([\n",
    "        ('Convertir',CategoricaSize()),\n",
    "        ('OneHotEncoder_size', OneHotEncoder(sparse_output=False, handle_unknown='ignore', min_frequency=min_freq))\n",
    "    ])\n",
    "\n",
    "    preprocesamiento = Pipeline([\n",
    "        ('inv', InvertirTransformer()),\n",
    "        ('brand_cluster', BrandClusterTransformer(n_clusters=3)),\n",
    "        ('xy_cluster', XYClusterTransformer()),\n",
    "        ('column_transform', ColumnTransformer([\n",
    "            ('std', trans_stand, lista_stand),\n",
    "            ('enc', trans_categoricas, lista_categoricas),\n",
    "            ('tmp', trans_temporales, lista_temporales),\n",
    "            ('con', trans_convertir, lista_convertir)\n",
    "        ]))\n",
    "    ])  \n",
    "\n",
    "    preprocesamiento.set_output(transform='pandas')\n",
    "\n",
    "    # Entrenamos con lo optimizado\n",
    "    model = XGBClassifier(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        max_leaves=max_leaves,\n",
    "        min_child_weight=min_child_weight,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "    # Pipeline con el modelo y transformaci√≥n\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocesamiento', preprocesamiento),\n",
    "        ('xgboost classifier', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Guardamos\n",
    "    trial.set_user_attr(\"best_pipeline\", pipeline)\n",
    "\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finamos una semilla para reproducibilidad\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, timeout=300)  # por 5 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"N√∫mero de trials:\", len(study.trials))\n",
    "print(\"Mejor MAE:\", study.best_value)\n",
    "print(\"Mejores hiperpar√°metros:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo\n",
    "model_xgb_optuna = study.best_trial.user_attrs[\"best_pipeline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtiene el clasification_report\n",
    "y_pred_XGBC_optuna= model_xgb_optuna.predict(X_test)\n",
    "\n",
    "print('Reporte de desempe√±o del modelo XGBoost Classifier: ')\n",
    "print(classification_report(y_test, y_pred_XGBC_optuna))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Interpretabilidad [1.0 puntos]\n",
    "\n",
    "En esta secci√≥n, deben explicar el funcionamiento de su modelo utilizando las t√©cnicas de interpretabilidad vistas en clase, como `SHAP`. Se espera que sean capaces de descomponer las predicciones y evaluar la importancia de los atributos y las interacciones entre ellos, con el fin de obtener una comprensi√≥n m√°s profunda de c√≥mo el modelo toma decisiones. \n",
    "\n",
    "Al desarrollar esta parte, deber√°n responder las siguientes preguntas clave como m√≠nimo:\n",
    "\n",
    "- ¬øPodr√≠a explicar el funcionamiento de su modelo para una predicci√≥n en particular? Si es as√≠, proporcione al menos tres ejemplos espec√≠ficos, describiendo c√≥mo el modelo lleg√≥ a sus decisiones y qu√© factores fueron m√°s relevantes en cada caso.\n",
    "\n",
    "- ¬øQu√© atributo tiene una mayor importancia en la salida de su modelo? Analice si esto tiene sentido con el problema planteado y justifique la relevancia de dicho atributo en el contexto de las predicciones que se realizan.\n",
    "\n",
    "- ¬øExiste alguna interacci√≥n entre atributos que sea relevante para el modelo? Investigue si la combinaci√≥n de ciertos atributos tiene un impacto significativo en las predicciones y expl√≠quela en **detalle**.\n",
    "\n",
    "- ¬øPodr√≠a existir sesgo hacia alg√∫n atributo en particular? Reflexione sobre la posibilidad de que el modelo est√© favoreciendo ciertos atributos. Si es as√≠, ¬øcu√°l podr√≠a ser la causa y qu√© impacto podr√≠a tener esto en la predicci√≥n?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se comenzaran observando las importancias de las features de manera global:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Se obtiene el orden de las features\n",
    "order = model_xgb_optuna.named_steps['xgboost classifier'].get_booster().feature_names\n",
    "\n",
    "# Se implementa un metodo de permutacion para observar la importancia de features\n",
    "result = permutation_importance(model_xgb_optuna, X_test, y_test, n_repeats=1, random_state=42)\n",
    "\n",
    "# Se visualiza en un grafico\n",
    "perm_sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "new_order = []\n",
    "for i in range(perm_sorted_idx.shape[0]-1, -1, -1):\n",
    "    new_order = np.append(new_order, order[perm_sorted_idx[i]])\n",
    "\n",
    "plt.boxplot(\n",
    "    result.importances[perm_sorted_idx].T,\n",
    "    vert=False,\n",
    "    labels = new_order\n",
    ")\n",
    "plt.title(\"Importancia de las Features por Incremento del Error\")\n",
    "plt.xlabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Si se observa el gr√°fico de importancia ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ahora, se intentar√° explicar el funcionamiento del modelo para ciertas predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define el explainer del mdelo\n",
    "import shap \n",
    "\n",
    "# Se transforma X_test para utilizar en explainer, ya que explainer solo acepta el modelo xgboost\n",
    "X_train_transformado = preprocesamiento.fit_transform(X_train)\n",
    "X_test_transformado = preprocesamiento.transform(X_test)\n",
    "explainer = shap.TreeExplainer(pipeline_XGBC.named_steps['xgboost classifier'])\n",
    "shap_values = explainer(X_test_transformado)\n",
    "\n",
    "# transformar logits a probabilidad\n",
    "np.exp(shap_values.base_values) / (1 + np.exp(shap_values.base_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer ejemplo\n",
    "idx_muestra = 1\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, \n",
    "                shap_values.values[idx_muestra,:], \n",
    "                X_test_transformado.iloc[idx_muestra,:],\n",
    "                link=\"logit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segundo ejemplo\n",
    "idx_muestra = 2\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, \n",
    "                shap_values.values[idx_muestra,:], \n",
    "                X_test_transformado.iloc[idx_muestra,:],\n",
    "                link=\"logit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tercer ejemplo\n",
    "idx_muestra = 3\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, \n",
    "                shap_values.values[idx_muestra,:], \n",
    "                X_test_transformado.iloc[idx_muestra,:],\n",
    "                link=\"logit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Resultados y Conclusiones [1.0 puntos]\n",
    "\n",
    "Para finalizar, se deben explicar los desarrollos y resultados obtenidos a lo largo de todo el proceso, desde la selecci√≥n de las variables hasta la optimizaci√≥n de hiperpar√°metros e interpretaci√≥n. Se espera una reflexi√≥n cr√≠tica sobre el desempe√±o de los modelos entrenados y una comparaci√≥n entre los diferentes enfoques. Adem√°s, deber√°n abordar los siguientes puntos clave:\n",
    "\n",
    "- **An√°lisis de m√©tricas**: Comenten sobre las m√©tricas obtenidas en cada etapa del modelo, destacando las m√°s relevantes como precisi√≥n, recall, F1-score, etc. ¬øCu√°les fueron los modelos m√°s efectivos? ¬øQu√© diferencias notables encontr√≥ entre ellos?\n",
    "\n",
    "- **Impacto de las decisiones tomadas**: Reflexionen sobre c√≥mo las decisiones relacionadas con el preprocesamiento, selecci√≥n de atributos y optimizaci√≥n de hiperpar√°metros influyeron en los resultados finales. ¬øHubo alguna decisi√≥n que haya tenido un impacto notable en el rendimiento?\n",
    "\n",
    "- **Lecciones aprendidas**: Concluyan sobre las lecciones m√°s importantes que aprendieron durante el proceso y c√≥mo estas pueden influir en futuras iteraciones del modelo. ¬øQu√© se podr√≠a mejorar si se repitiera el proceso? Si tuvieran m√°s recursos y tiempo, ¬øqu√© otras t√©cnicas/herramientas habr√≠an utilizado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [Escriba aqu√≠ sus resultados]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mucho √©xito!\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExaHpvOTY5Z3hpdHI3aDBpdGRueXRqamZncXp2emFrbjJ5M2s5eTR1dSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/1PMVNNKVIL8Ig/giphy.gif\" width=\"300\" height=\"200\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
